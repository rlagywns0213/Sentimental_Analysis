{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집 및 불러오기\n",
    "\n",
    "- bert_avengers_crawling.ipynb 참고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:14:00.472170Z",
     "start_time": "2021-04-20T07:14:00.456212Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:14:00.757889Z",
     "start_time": "2021-04-20T07:14:00.631227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 shape :  (7996, 2)\n",
      "데이터의 긍정 부정 비율 : \n",
      " 1    3998\n",
      "0    3998\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>스포일러가 포함된 감상평입니다. 감상평 보기아이언맨으로 시작해서 아이언맨으로 끝나는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>첨볼땐 와~하고봤는데 두번볼때 울었네ㅜㅜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>마블펜이라면 무조건 봐야하는 영화... 진짜 처음에 아이언맨1편 나오고 토르1편나올...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>토니스타크 정말 감동이었고 뭔가 세드렌딩이면서 모두를 구한 해피엔딩이라 재미있게 봤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>스포일러가 포함된 감상평입니다. 감상평 보기지금은 늣었지만 아이언맨 존경합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>0</td>\n",
       "      <td>관람객그냥 괜찮네용괜찮아ㅇㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>0</td>\n",
       "      <td>관람객2시간 넘는 시간동안 영화가좀 지루해서 몸을 배배꼬꼬 여러차레자세를 바꾸고 하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0</td>\n",
       "      <td>관람객마블팬도 뭣도 아닌 입장에서 순수하게 봤을때 스토리 진행도 진부하고 액션이나 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0</td>\n",
       "      <td>볼만한데 전 작품들보다 연출, 편집, 오락성등등 모든게 부족했던것같아요~ 너무 기대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0</td>\n",
       "      <td>잤어 재미없어서 다들 지루하</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document\n",
       "0         1  스포일러가 포함된 감상평입니다. 감상평 보기아이언맨으로 시작해서 아이언맨으로 끝나는...\n",
       "1         1                             첨볼땐 와~하고봤는데 두번볼때 울었네ㅜㅜ\n",
       "2         1  마블펜이라면 무조건 봐야하는 영화... 진짜 처음에 아이언맨1편 나오고 토르1편나올...\n",
       "3         1  토니스타크 정말 감동이었고 뭔가 세드렌딩이면서 모두를 구한 해피엔딩이라 재미있게 봤...\n",
       "4         1        스포일러가 포함된 감상평입니다. 감상평 보기지금은 늣었지만 아이언맨 존경합니다\n",
       "...     ...                                                ...\n",
       "7991      0                                    관람객그냥 괜찮네용괜찮아ㅇㅇ\n",
       "7992      0  관람객2시간 넘는 시간동안 영화가좀 지루해서 몸을 배배꼬꼬 여러차레자세를 바꾸고 하...\n",
       "7993      0  관람객마블팬도 뭣도 아닌 입장에서 순수하게 봤을때 스토리 진행도 진부하고 액션이나 ...\n",
       "7994      0  볼만한데 전 작품들보다 연출, 편집, 오락성등등 모든게 부족했던것같아요~ 너무 기대...\n",
       "7995      0                                    잤어 재미없어서 다들 지루하\n",
       "\n",
       "[7996 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv',names = ['label', 'document'])\n",
    "worst_train = pd.read_csv('worst_train.csv',names = ['label', 'document'])\n",
    "    \n",
    "class data():        \n",
    "    def best_data(self):\n",
    "        # 5만개 수집만개 수집 (별점 7점이상)\n",
    "        best_train = train[train.label==1]\n",
    "        best_train = best_train.dropna()\n",
    "        best_df = best_train[:3998] #수집한 부정 데이터와 개수 동일 유지\n",
    "        return best_df\n",
    "\n",
    "    def worst_data(self):\n",
    "        worst_df = worst_train.dropna()\n",
    "        return worst_df\n",
    "\n",
    "    def train_test_merge(self,best_df1, worst_df1):\n",
    "        train = pd.concat([best_df1, worst_df1])\n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        print(\"데이터의 shape : \", train.shape)\n",
    "        print(\"데이터의 긍정 부정 비율 : \\n\", train['label'].value_counts())\n",
    "        return train\n",
    "\n",
    "data = data()\n",
    "best_df = data.best_data()\n",
    "worst_df = data.worst_data()\n",
    "train = data.train_test_merge(best_df, worst_df)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스포일러 포함 감상평 문구 제거\n",
    "\n",
    "#### 형태소 분석기 1 : okt 라이브러리 사용\n",
    "- norm옵션 : 정규화 안녕하세욬ㅋㅋ=> 안녕하세요\n",
    "- stem옵션 : 원형을 찾아주는 옵션 (그래요 -> 그렇다)\n",
    "\n",
    "\n",
    "- **은,는,이,가 조사 위주의 불용어 제거**\n",
    "- 영화리뷰에 영향많이 미치지 않을 것\n",
    "\n",
    "#### 형태소 분석기 2: mecab 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.006155Z",
     "start_time": "2021-04-20T07:14:01.499943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>token_okt1</th>\n",
       "      <th>token_okt2</th>\n",
       "      <th>token_mecab1</th>\n",
       "      <th>token_mecab2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>아이언맨으로 시작해서 아이언맨으로 끝나는 엄청난 시나리오다배우들의 연기도 엄청났다또...</td>\n",
       "      <td>[아이언맨/Noun, 으로/Josa, 시작/Noun, 하다/Verb, 아이언맨/No...</td>\n",
       "      <td>[아이언맨/Noun, 시작/Noun, 하다/Verb, 아이언맨/Noun, 끝나다/V...</td>\n",
       "      <td>[아이언맨, 으로, 시작, 해서, 아이언맨, 으로, 끝, 나, 는, 엄청난, 시나리...</td>\n",
       "      <td>[아이언맨, 으로, 시작, 해서, 아이언맨, 으로, 끝, 나, 엄청난, 시나리오, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>첨볼땐 와~하고봤는데 두번볼때 울었네ㅜㅜ</td>\n",
       "      <td>[첨/Adverb, 볼땐/Noun, 오다/Verb, ~/Punctuation, 하다...</td>\n",
       "      <td>[첨/Adverb, 볼땐/Noun, 오다/Verb, ~/Punctuation, 하다...</td>\n",
       "      <td>[첨, 볼땐, 와, ~, 하, 고, 봤, 는데, 두, 번, 볼, 때, 울, 었, 네...</td>\n",
       "      <td>[첨, 볼땐, ~, 봤, 는데, 두, 번, 볼, 때, 울, 었, ㅜㅜ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>마블펜이라면 무조건 봐야하는 영화... 진짜 처음에 아이언맨1편 나오고 토르1편나올...</td>\n",
       "      <td>[마블/Noun, 펜/Noun, 이/Determiner, 라면/Noun, 무조건/N...</td>\n",
       "      <td>[마블/Noun, 펜/Noun, 이/Determiner, 라면/Noun, 무조건/N...</td>\n",
       "      <td>[마블, 펜, 이, 라면, 무조건, 봐야, 하, 는, 영화, ., .., 진짜, 처...</td>\n",
       "      <td>[마블, 펜, 라면, 무조건, 봐야, 영화, ., .., 진짜, 처음, 아이언맨, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>토니스타크 정말 감동이었고 뭔가 세드렌딩이면서 모두를 구한 해피엔딩이라 재미있게 봤...</td>\n",
       "      <td>[토니스타크/Noun, 정말/Noun, 감동/Noun, 이다/Verb, 뭔가/Nou...</td>\n",
       "      <td>[토니스타크/Noun, 정말/Noun, 감동/Noun, 이다/Verb, 뭔가/Nou...</td>\n",
       "      <td>[토니, 스타크, 정말, 감동, 이, 었, 고, 뭔가, 세드, 렌, 딩, 이, 면서...</td>\n",
       "      <td>[토니, 스타크, 정말, 감동, 었, 뭔가, 세드, 렌, 딩, 면서, 모두, 구한,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>지금은 늣었지만 아이언맨 존경합니다</td>\n",
       "      <td>[지금/Noun, 은/Josa, 늣었/Noun, 지만/Josa, 아이언맨/Noun,...</td>\n",
       "      <td>[지금/Noun, 늣었/Noun, 아이언맨/Noun, 존경/Noun, 하다/Verb]</td>\n",
       "      <td>[지금, 은, 늣, 었, 지만, 아이언맨, 존경, 합니다]</td>\n",
       "      <td>[지금, 늣, 었, 지만, 아이언맨, 존경, 합니다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>0</td>\n",
       "      <td>관람객그냥 괜찮네용괜찮아ㅇㅇ</td>\n",
       "      <td>[관람객/Noun, 그냥/Noun, 괜찮다/Adjective, 네/Determine...</td>\n",
       "      <td>[관람객/Noun, 그냥/Noun, 괜찮다/Adjective, 네/Determine...</td>\n",
       "      <td>[관람객, 그냥, 괜찮, 네, 용, 괜찮, 아, ㅇㅇ]</td>\n",
       "      <td>[관람객, 그냥, 괜찮, 용, 괜찮, 아, ㅇㅇ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>0</td>\n",
       "      <td>관람객2시간 넘는 시간동안 영화가좀 지루해서 몸을 배배꼬꼬 여러차레자세를 바꾸고 하...</td>\n",
       "      <td>[관람객/Noun, 2시간/Number, 넘다/Verb, 시간/Noun, 동안/No...</td>\n",
       "      <td>[관람객/Noun, 2시간/Number, 넘다/Verb, 시간/Noun, 동안/No...</td>\n",
       "      <td>[관람객, 2, 시간, 넘, 는, 시간, 동안, 영화, 가, 좀, 지루, 해서, 몸...</td>\n",
       "      <td>[관람객, 2, 시간, 넘, 시간, 동안, 영화, 좀, 지루, 해서, 몸, 배배, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0</td>\n",
       "      <td>관람객마블팬도 뭣도 아닌 입장에서 순수하게 봤을때 스토리 진행도 진부하고 액션이나 ...</td>\n",
       "      <td>[관람객/Noun, 마블/Noun, 팬/Noun, 도/Josa, 뭣/Noun, 도/...</td>\n",
       "      <td>[관람객/Noun, 마블/Noun, 팬/Noun, 뭣/Noun, 아니다/Adject...</td>\n",
       "      <td>[관람객, 마블, 팬, 도, 뭣, 도, 아닌, 입장, 에서, 순수, 하, 게, 봤,...</td>\n",
       "      <td>[관람객, 마블, 팬, 뭣, 아닌, 입장, 에서, 순수, 봤, 때, 스토리, 진행,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0</td>\n",
       "      <td>볼만한데 전 작품들보다 연출, 편집, 오락성등등 모든게 부족했던것같아요~ 너무 기대...</td>\n",
       "      <td>[볼/Noun, 만/Josa, 한/Determiner, 데/Noun, 전/Noun,...</td>\n",
       "      <td>[볼/Noun, 한/Determiner, 데/Noun, 전/Noun, 작품/Noun...</td>\n",
       "      <td>[볼, 만, 한데, 전, 작품, 들, 보다, 연출, ,, 편집, ,, 오락, 성, ...</td>\n",
       "      <td>[볼, 한데, 전, 작품, 보다, 연출, ,, 편집, ,, 오락, 성, 등등, 모든...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0</td>\n",
       "      <td>잤어 재미없어서 다들 지루하</td>\n",
       "      <td>[자다/Verb, 재미없다/Adjective, 다/Adverb, 들다/Verb, 지...</td>\n",
       "      <td>[자다/Verb, 재미없다/Adjective, 다/Adverb, 들다/Verb, 지...</td>\n",
       "      <td>[잤, 어, 재미없, 어서, 다, 들, 지루, 하]</td>\n",
       "      <td>[잤, 어, 재미없, 어서, 지루]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7996 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document  \\\n",
       "0         1  아이언맨으로 시작해서 아이언맨으로 끝나는 엄청난 시나리오다배우들의 연기도 엄청났다또...   \n",
       "1         1                             첨볼땐 와~하고봤는데 두번볼때 울었네ㅜㅜ   \n",
       "2         1  마블펜이라면 무조건 봐야하는 영화... 진짜 처음에 아이언맨1편 나오고 토르1편나올...   \n",
       "3         1  토니스타크 정말 감동이었고 뭔가 세드렌딩이면서 모두를 구한 해피엔딩이라 재미있게 봤...   \n",
       "4         1                                지금은 늣었지만 아이언맨 존경합니다   \n",
       "...     ...                                                ...   \n",
       "7991      0                                    관람객그냥 괜찮네용괜찮아ㅇㅇ   \n",
       "7992      0  관람객2시간 넘는 시간동안 영화가좀 지루해서 몸을 배배꼬꼬 여러차레자세를 바꾸고 하...   \n",
       "7993      0  관람객마블팬도 뭣도 아닌 입장에서 순수하게 봤을때 스토리 진행도 진부하고 액션이나 ...   \n",
       "7994      0  볼만한데 전 작품들보다 연출, 편집, 오락성등등 모든게 부족했던것같아요~ 너무 기대...   \n",
       "7995      0                                    잤어 재미없어서 다들 지루하   \n",
       "\n",
       "                                             token_okt1  \\\n",
       "0     [아이언맨/Noun, 으로/Josa, 시작/Noun, 하다/Verb, 아이언맨/No...   \n",
       "1     [첨/Adverb, 볼땐/Noun, 오다/Verb, ~/Punctuation, 하다...   \n",
       "2     [마블/Noun, 펜/Noun, 이/Determiner, 라면/Noun, 무조건/N...   \n",
       "3     [토니스타크/Noun, 정말/Noun, 감동/Noun, 이다/Verb, 뭔가/Nou...   \n",
       "4     [지금/Noun, 은/Josa, 늣었/Noun, 지만/Josa, 아이언맨/Noun,...   \n",
       "...                                                 ...   \n",
       "7991  [관람객/Noun, 그냥/Noun, 괜찮다/Adjective, 네/Determine...   \n",
       "7992  [관람객/Noun, 2시간/Number, 넘다/Verb, 시간/Noun, 동안/No...   \n",
       "7993  [관람객/Noun, 마블/Noun, 팬/Noun, 도/Josa, 뭣/Noun, 도/...   \n",
       "7994  [볼/Noun, 만/Josa, 한/Determiner, 데/Noun, 전/Noun,...   \n",
       "7995  [자다/Verb, 재미없다/Adjective, 다/Adverb, 들다/Verb, 지...   \n",
       "\n",
       "                                             token_okt2  \\\n",
       "0     [아이언맨/Noun, 시작/Noun, 하다/Verb, 아이언맨/Noun, 끝나다/V...   \n",
       "1     [첨/Adverb, 볼땐/Noun, 오다/Verb, ~/Punctuation, 하다...   \n",
       "2     [마블/Noun, 펜/Noun, 이/Determiner, 라면/Noun, 무조건/N...   \n",
       "3     [토니스타크/Noun, 정말/Noun, 감동/Noun, 이다/Verb, 뭔가/Nou...   \n",
       "4       [지금/Noun, 늣었/Noun, 아이언맨/Noun, 존경/Noun, 하다/Verb]   \n",
       "...                                                 ...   \n",
       "7991  [관람객/Noun, 그냥/Noun, 괜찮다/Adjective, 네/Determine...   \n",
       "7992  [관람객/Noun, 2시간/Number, 넘다/Verb, 시간/Noun, 동안/No...   \n",
       "7993  [관람객/Noun, 마블/Noun, 팬/Noun, 뭣/Noun, 아니다/Adject...   \n",
       "7994  [볼/Noun, 한/Determiner, 데/Noun, 전/Noun, 작품/Noun...   \n",
       "7995  [자다/Verb, 재미없다/Adjective, 다/Adverb, 들다/Verb, 지...   \n",
       "\n",
       "                                           token_mecab1  \\\n",
       "0     [아이언맨, 으로, 시작, 해서, 아이언맨, 으로, 끝, 나, 는, 엄청난, 시나리...   \n",
       "1     [첨, 볼땐, 와, ~, 하, 고, 봤, 는데, 두, 번, 볼, 때, 울, 었, 네...   \n",
       "2     [마블, 펜, 이, 라면, 무조건, 봐야, 하, 는, 영화, ., .., 진짜, 처...   \n",
       "3     [토니, 스타크, 정말, 감동, 이, 었, 고, 뭔가, 세드, 렌, 딩, 이, 면서...   \n",
       "4                      [지금, 은, 늣, 었, 지만, 아이언맨, 존경, 합니다]   \n",
       "...                                                 ...   \n",
       "7991                     [관람객, 그냥, 괜찮, 네, 용, 괜찮, 아, ㅇㅇ]   \n",
       "7992  [관람객, 2, 시간, 넘, 는, 시간, 동안, 영화, 가, 좀, 지루, 해서, 몸...   \n",
       "7993  [관람객, 마블, 팬, 도, 뭣, 도, 아닌, 입장, 에서, 순수, 하, 게, 봤,...   \n",
       "7994  [볼, 만, 한데, 전, 작품, 들, 보다, 연출, ,, 편집, ,, 오락, 성, ...   \n",
       "7995                       [잤, 어, 재미없, 어서, 다, 들, 지루, 하]   \n",
       "\n",
       "                                           token_mecab2  \n",
       "0     [아이언맨, 으로, 시작, 해서, 아이언맨, 으로, 끝, 나, 엄청난, 시나리오, ...  \n",
       "1               [첨, 볼땐, ~, 봤, 는데, 두, 번, 볼, 때, 울, 었, ㅜㅜ]  \n",
       "2     [마블, 펜, 라면, 무조건, 봐야, 영화, ., .., 진짜, 처음, 아이언맨, ...  \n",
       "3     [토니, 스타크, 정말, 감동, 었, 뭔가, 세드, 렌, 딩, 면서, 모두, 구한,...  \n",
       "4                         [지금, 늣, 었, 지만, 아이언맨, 존경, 합니다]  \n",
       "...                                                 ...  \n",
       "7991                        [관람객, 그냥, 괜찮, 용, 괜찮, 아, ㅇㅇ]  \n",
       "7992  [관람객, 2, 시간, 넘, 시간, 동안, 영화, 좀, 지루, 해서, 몸, 배배, ...  \n",
       "7993  [관람객, 마블, 팬, 뭣, 아닌, 입장, 에서, 순수, 봤, 때, 스토리, 진행,...  \n",
       "7994  [볼, 한데, 전, 작품, 보다, 연출, ,, 편집, ,, 오락, 성, 등등, 모든...  \n",
       "7995                                [잤, 어, 재미없, 어서, 지루]  \n",
       "\n",
       "[7996 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()\n",
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")\n",
    "\n",
    "\n",
    "class preprocessing():\n",
    "    def __init__(self):\n",
    "            # 스포일러 포함 감상평 문구 제거\n",
    "        def reduce_spoil(self):\n",
    "            train.document = train.document.apply(lambda x:x.replace('스포일러가 포함된 감상평입니다. 감상평 보기',''))\n",
    "            return train\n",
    "        self.train = reduce_spoil(train)\n",
    "        self.train2 = reduce_spoil(train)\n",
    "    \n",
    "    def analysis(self):\n",
    "        def tokenize1(doc):\n",
    "            # norm은 정규화, stem은 근어로 표시하기를 나타냄\n",
    "            return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)] \n",
    "        def tokenize2(doc):\n",
    "            # 조사 관련 형태소는 없애주기 위함\n",
    "            word = ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True) if 'Josa' not in t]\n",
    "            return word\n",
    "        train['token_okt1'] = train['document'].apply(tokenize1)\n",
    "        train['token_okt2'] = train['document'].apply(tokenize2)\n",
    "\n",
    "        # 조사 및 괄호를 불용어로 정의\n",
    "        stopwords = ['(',')','도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '음', '면']\n",
    "        train['token_mecab1'] = train['document'].apply(mecab.morphs)\n",
    "        train['token_mecab2'] = train['token_mecab1'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "        return train\n",
    "    \n",
    "preprocess = preprocessing()\n",
    "train = preprocess.analysis()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.036077Z",
     "start_time": "2021-04-20T07:16:24.008149Z"
    }
   },
   "outputs": [],
   "source": [
    " def train_test(self):\n",
    "        train_data, test_data =  train_test_split(train, train['label'], test_size = 0.25, random_state = 42)\n",
    "        print('훈련용 리뷰의 개수 :', len(train_data))\n",
    "        print('테스트용 리뷰의 개수 :', len(test_data))\n",
    "        return train_data, test_data\n",
    "    \n",
    "train_data, test_data = train_test_split(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정수 인코딩\n",
    "\n",
    "- dictonary, nltk 패키지를 이용할 수도 있지만, keras에서 텍스트 처리에 자동으로 단어 빈도가 높은 단어의 인덱스는 낮게끔 설정해준다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.487383Z",
     "start_time": "2021-04-20T07:16:24.039067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_Train, X_test, y_test (5997,) (5997,) (1999,) (1999,)\n",
      "\n",
      "단어 집합(vocabulary)의 크기 : 6854\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 3205\n",
      "단어 집합에서 희귀 단어의 비율: 46.76101546542165\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.89485708730313\n",
      "\n",
      "vocab size : 3651\n",
      "\n",
      "리뷰의 최대 길이 : 64\n",
      "리뷰의 평균 길이 : 13.721527430381858\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토큰 방법을 입력, 단어 빈도 수\n",
    "def convert_input(token_analysis,how_many):\n",
    "    X_train = train_data[token_analysis].values\n",
    "    y_train = train_data['label']\n",
    "    X_test= test_data[token_analysis].values\n",
    "    y_test = test_data['label']\n",
    "    print('X_train, y_Train, X_test, y_test', X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "     # 정수인코딩\n",
    "    tokenizer = Tokenizer( oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    threshold = how_many\n",
    "    total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('\\n단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "   \n",
    "\n",
    "    # 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "    # 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "    vocab_size = total_cnt - rare_cnt + 2\n",
    "    print('\\nvocab size :',vocab_size)\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    print('\\n리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "    print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "    plt.hist([len(s) for s in X_train], bins=50)\n",
    "    plt.xlabel('length of samples')\n",
    "    plt.ylabel('number of samples')\n",
    "    plt.show()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, vocab_size\n",
    "\n",
    "X_train, y_train, X_test, y_test, vocab_size = convert_input('token_okt1',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.502338Z",
     "start_time": "2021-04-20T07:16:24.489371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.74987493746873\n",
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.79989994997499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padding_len(max_len, sentences):\n",
    "    cnt = 0\n",
    "    for s in sentences:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(sentences))*100))\n",
    "    return max_len\n",
    "padding_len(55, X_train)\n",
    "padding_len(55, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.562181Z",
     "start_time": "2021-04-20T07:16:24.503335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5997, 55) (1999, 55)\n"
     ]
    }
   ],
   "source": [
    "def padding(max_len):\n",
    "    x_train = pad_sequences(X_train, maxlen = max_len)\n",
    "    x_test = pad_sequences(X_test, maxlen = max_len)\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    return x_train, x_test, max_len\n",
    "\n",
    "X_train, X_test, max_len = padding(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DNN 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.577142Z",
     "start_time": "2021-04-20T07:16:24.565174Z"
    }
   },
   "outputs": [],
   "source": [
    "def DNN():\n",
    "    # 모델 구조 정의하기\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(layers.Dense(128, activation='relu')) \n",
    "    model.add(layers.Dense(128, activation='relu')) #ReLU 활성화함수 채택\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append((token, 'DNN',score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LSTM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.593108Z",
     "start_time": "2021-04-20T07:16:24.580133Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append((token, 'LSTM',score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LSTM 2층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:16:24.608059Z",
     "start_time": "2021-04-20T07:16:24.595093Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_2_layer():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(LSTM(128, return_sequences=True,activation='relu'))\n",
    "    model.add(LSTM(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append((token, 'LSTM_2layer',score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:19:54.322817Z",
     "start_time": "2021-04-20T07:19:54.316860Z"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(Bidirectional(LSTM(128,activation='relu')))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append((token, 'Bi-LSTM',score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bidirectional lstm(2_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:21:40.285804Z",
     "start_time": "2021-04-20T07:21:40.278822Z"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm_2():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True,activation='relu')))\n",
    "    model.add(Bidirectional(LSTM(128,activation='relu')))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append((token, 'Bi-LSTM-2',score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T07:22:49.135989Z",
     "start_time": "2021-04-20T07:22:49.129008Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "def cnn_1D():\n",
    "    model = Sequential()    \n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(Conv1D(256, 3, padding='valid', activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append((token, '1D-CNN',score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 결과 한번에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:40:47.465902Z",
     "start_time": "2021-04-20T07:23:01.871537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_okt1 방식 진행합니다.\n",
      "\n",
      "X_train, y_Train, X_test, y_test (5997,) (5997,) (1999,) (1999,)\n",
      "\n",
      "단어 집합(vocabulary)의 크기 : 6854\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 3205\n",
      "단어 집합에서 희귀 단어의 비율: 46.76101546542165\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.89485708730313\n",
      "\n",
      "vocab size : 3651\n",
      "\n",
      "리뷰의 최대 길이 : 64\n",
      "리뷰의 평균 길이 : 13.721527430381858\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.74987493746873\n",
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.79989994997499\n",
      "(5997, 55) (1999, 55)\n",
      "\n",
      "DNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.6805 - acc: 0.5552\n",
      "Epoch 00001: val_acc improved from -inf to 0.56339, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.6801 - acc: 0.5568 - val_loss: 0.6774 - val_acc: 0.5634\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6703 - acc: 0.5719\n",
      "Epoch 00002: val_acc improved from 0.56339 to 0.56421, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6703 - acc: 0.5719 - val_loss: 0.6761 - val_acc: 0.5642\n",
      "Epoch 3/30\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.6673 - acc: 0.5727\n",
      "Epoch 00003: val_acc improved from 0.56421 to 0.56462, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6670 - acc: 0.5732 - val_loss: 0.6777 - val_acc: 0.5646\n",
      "Epoch 4/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6656 - acc: 0.5731\n",
      "Epoch 00004: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6657 - acc: 0.5738 - val_loss: 0.6786 - val_acc: 0.5642\n",
      "Epoch 5/30\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.6644 - acc: 0.5734\n",
      "Epoch 00005: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6646 - acc: 0.5739 - val_loss: 0.6785 - val_acc: 0.5641\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6644 - acc: 0.5739\n",
      "Epoch 00006: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6644 - acc: 0.5739 - val_loss: 0.6802 - val_acc: 0.5637\n",
      "Epoch 7/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6647 - acc: 0.5709\n",
      "Epoch 00007: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6646 - acc: 0.5712 - val_loss: 0.6811 - val_acc: 0.5634\n",
      "Epoch 8/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6641 - acc: 0.5731\n",
      "Epoch 00008: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.6639 - acc: 0.5740 - val_loss: 0.6831 - val_acc: 0.5642\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6638 - acc: 0.5741\n",
      "Epoch 00009: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6638 - acc: 0.5741 - val_loss: 0.6817 - val_acc: 0.5643\n",
      "Epoch 10/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6635 - acc: 0.5753\n",
      "Epoch 00010: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6636 - acc: 0.5742 - val_loss: 0.6840 - val_acc: 0.5642\n",
      "Epoch 11/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6633 - acc: 0.5745\n",
      "Epoch 00011: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6634 - acc: 0.5743 - val_loss: 0.6839 - val_acc: 0.5637\n",
      "Epoch 12/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6630 - acc: 0.5747\n",
      "Epoch 00012: val_acc did not improve from 0.56462\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6630 - acc: 0.5744 - val_loss: 0.6874 - val_acc: 0.5640\n",
      "Epoch 00012: early stopping\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6795 - acc: 0.5467\n",
      "테스트 정확도: 0.5467\n",
      "\n",
      "LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5439 - acc: 0.7323\n",
      "Epoch 00001: val_acc improved from -inf to 0.78917, saving model to best_model.h5\n",
      "150/150 [==============================] - 8s 52ms/step - loss: 0.5439 - acc: 0.7323 - val_loss: 0.4657 - val_acc: 0.7892\n",
      "Epoch 2/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8570\n",
      "Epoch 00002: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.3540 - acc: 0.8568 - val_loss: 0.5293 - val_acc: 0.7808\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2876 - acc: 0.8895\n",
      "Epoch 00003: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 9s 62ms/step - loss: 0.2876 - acc: 0.8895 - val_loss: 0.5298 - val_acc: 0.7750\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.9081\n",
      "Epoch 00004: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.2436 - acc: 0.9081 - val_loss: 0.5748 - val_acc: 0.7758\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2085 - acc: 0.9245\n",
      "Epoch 00005: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.2085 - acc: 0.9245 - val_loss: 0.6473 - val_acc: 0.7733\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1920 - acc: 0.9283\n",
      "Epoch 00006: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.1920 - acc: 0.9283 - val_loss: 0.6364 - val_acc: 0.7667\n",
      "Epoch 7/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9348\n",
      "Epoch 00007: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.1698 - acc: 0.9348 - val_loss: 0.7532 - val_acc: 0.7733\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9381\n",
      "Epoch 00008: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.1492 - acc: 0.9377 - val_loss: 0.8065 - val_acc: 0.7750\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1363 - acc: 0.9420\n",
      "Epoch 00009: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.1363 - acc: 0.9420 - val_loss: 0.8493 - val_acc: 0.7725\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1272 - acc: 0.9454\n",
      "Epoch 00010: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 0.1272 - acc: 0.9454 - val_loss: 0.9353 - val_acc: 0.7575\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1138 - acc: 0.9466\n",
      "Epoch 00011: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 9s 63ms/step - loss: 0.1138 - acc: 0.9466 - val_loss: 1.0481 - val_acc: 0.7558\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.4664 - acc: 0.7929\n",
      "테스트 정확도: 0.7929\n",
      "\n",
      "LSTM_2layer 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0905 - acc: 0.7019\n",
      "Epoch 00001: val_acc improved from -inf to 0.79667, saving model to best_model.h5\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 1.0905 - acc: 0.7019 - val_loss: 0.8598 - val_acc: 0.7967\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.7886 - acc: 0.6504\n",
      "Epoch 00002: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 18s 121ms/step - loss: 2.7886 - acc: 0.6504 - val_loss: 0.6030 - val_acc: 0.6758\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 80.8103 - acc: 0.6339\n",
      "Epoch 00003: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 80.8103 - acc: 0.6339 - val_loss: 0.6963 - val_acc: 0.4900\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6125 - acc: 0.5276\n",
      "Epoch 00004: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 19s 128ms/step - loss: 0.6125 - acc: 0.5276 - val_loss: 0.6421 - val_acc: 0.5367\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5617 - acc: 0.6650\n",
      "Epoch 00005: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.5617 - acc: 0.6650 - val_loss: 0.6552 - val_acc: 0.5967\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8442 - acc: 0.7705\n",
      "Epoch 00006: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 19s 126ms/step - loss: 0.8442 - acc: 0.7705 - val_loss: 0.6483 - val_acc: 0.7125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6209 - acc: 0.8276\n",
      "Epoch 00007: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.6209 - acc: 0.8276 - val_loss: 5.8023 - val_acc: 0.7208\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 8831.7324 - acc: 0.6496\n",
      "Epoch 00008: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 18s 121ms/step - loss: 8831.7324 - acc: 0.6496 - val_loss: 0.5880 - val_acc: 0.6692\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5404 - acc: 0.8040\n",
      "Epoch 00009: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.5404 - acc: 0.8040 - val_loss: 0.5680 - val_acc: 0.7000\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4268 - acc: 0.8418\n",
      "Epoch 00010: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 0.4268 - acc: 0.8418 - val_loss: 0.6046 - val_acc: 0.7575\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 11.7409 - acc: 0.8693\n",
      "Epoch 00011: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 11.7409 - acc: 0.8693 - val_loss: 0.5744 - val_acc: 0.7717\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3615 - acc: 0.8749\n",
      "Epoch 00012: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 18s 122ms/step - loss: 0.3615 - acc: 0.8749 - val_loss: 0.5736 - val_acc: 0.7750\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3704 - acc: 0.8708\n",
      "Epoch 00013: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.3704 - acc: 0.8708 - val_loss: 0.6250 - val_acc: 0.7725\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3411 - acc: 0.8818\n",
      "Epoch 00014: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 0.3411 - acc: 0.8818 - val_loss: 0.6103 - val_acc: 0.7758\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3047 - acc: 0.8851\n",
      "Epoch 00015: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.3047 - acc: 0.8851 - val_loss: 0.6628 - val_acc: 0.7717\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2885 - acc: 0.8866\n",
      "Epoch 00016: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 18s 123ms/step - loss: 0.2885 - acc: 0.8866 - val_loss: 0.6586 - val_acc: 0.7742\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2675 - acc: 0.8918- ETA: 1s - loss: 0.2690 -\n",
      "Epoch 00017: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.2675 - acc: 0.8918 - val_loss: 0.7135 - val_acc: 0.7725\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2493 - acc: 0.8972\n",
      "Epoch 00018: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.2493 - acc: 0.8972 - val_loss: 0.7921 - val_acc: 0.7767\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2330 - acc: 0.9022\n",
      "Epoch 00019: val_acc did not improve from 0.79667\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.2330 - acc: 0.9022 - val_loss: 0.7836 - val_acc: 0.7750\n",
      "Epoch 00019: early stopping\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.9855 - acc: 0.7899\n",
      "테스트 정확도: 0.7899\n",
      "\n",
      "Bi-LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7258 - acc: 0.6685\n",
      "Epoch 00001: val_acc improved from -inf to 0.77583, saving model to best_model.h5\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.7258 - acc: 0.6685 - val_loss: 0.6347 - val_acc: 0.7758\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.1760 - acc: 0.7611\n",
      "Epoch 00002: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.1760 - acc: 0.7611 - val_loss: 3.6290 - val_acc: 0.7375\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7263 - acc: 0.8166\n",
      "Epoch 00003: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.7263 - acc: 0.8166 - val_loss: 1.3963 - val_acc: 0.7692\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1449.3514 - acc: 0.8197\n",
      "Epoch 00004: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 1449.3514 - acc: 0.8197 - val_loss: 0.6487 - val_acc: 0.7392\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6456 - acc: 0.8120\n",
      "Epoch 00005: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.6456 - acc: 0.8120 - val_loss: 0.6288 - val_acc: 0.7608\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5939 - acc: 0.8301\n",
      "Epoch 00006: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 0.5939 - acc: 0.8301 - val_loss: 0.6001 - val_acc: 0.7633\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 193.0112 - acc: 0.7980\n",
      "Epoch 00007: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 193.0112 - acc: 0.7980 - val_loss: 0.5541 - val_acc: 0.7683\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.2683 - acc: 0.7767\n",
      "Epoch 00008: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 4.2683 - acc: 0.7767 - val_loss: 0.5843 - val_acc: 0.7625\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5071 - acc: 0.8274\n",
      "Epoch 00009: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.5071 - acc: 0.8274 - val_loss: 1628355.2500 - val_acc: 0.7642\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1025.8643 - acc: 0.7924\n",
      "Epoch 00010: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 1025.8643 - acc: 0.7924 - val_loss: 0.5439 - val_acc: 0.7642\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 8.4841 - acc: 0.8113\n",
      "Epoch 00011: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 8.4841 - acc: 0.8113 - val_loss: 0.5458 - val_acc: 0.7550\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5006 - acc: 0.8293\n",
      "Epoch 00012: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.5006 - acc: 0.8293 - val_loss: 0.5410 - val_acc: 0.7575\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.4037 - acc: 0.8366\n",
      "Epoch 00013: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 83ms/step - loss: 1.4037 - acc: 0.8366 - val_loss: 21.9347 - val_acc: 0.7725\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3878 - acc: 0.8566\n",
      "Epoch 00014: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 0.3878 - acc: 0.8566 - val_loss: 5.2759 - val_acc: 0.7725\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3454 - acc: 0.8645\n",
      "Epoch 00015: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.3454 - acc: 0.8645 - val_loss: 6.4346 - val_acc: 0.7742\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 391.6121 - acc: 0.8182- ET - ETA: 2s - loss: 49 - ETA: 0s - loss: 422.3058 - \n",
      "Epoch 00016: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 391.6121 - acc: 0.8182 - val_loss: 10.0719 - val_acc: 0.7325\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4193 - acc: 0.8407\n",
      "Epoch 00017: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 0.4193 - acc: 0.8407 - val_loss: 11.3128 - val_acc: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3767 - acc: 0.8657\n",
      "Epoch 00018: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.3767 - acc: 0.8657 - val_loss: 14.5919 - val_acc: 0.7608\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4359 - acc: 0.8553\n",
      "Epoch 00019: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.4359 - acc: 0.8553 - val_loss: 14.5247 - val_acc: 0.7592\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3594 - acc: 0.8616-\n",
      "Epoch 00020: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3594 - acc: 0.8616 - val_loss: 15.3589 - val_acc: 0.7525\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3408 - acc: 0.8683\n",
      "Epoch 00021: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 0.3408 - acc: 0.8683 - val_loss: 20.2185 - val_acc: 0.7508\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3294 - acc: 0.8712\n",
      "Epoch 00022: val_acc did not improve from 0.77583\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 0.3294 - acc: 0.8712 - val_loss: 22.6262 - val_acc: 0.7575\n",
      "Epoch 00022: early stopping\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.6382 - acc: 0.7704\n",
      "테스트 정확도: 0.7704\n",
      "\n",
      "Bi-LSTM 2층 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 66668848.0000 - acc: 0.6683\n",
      "Epoch 00001: val_acc improved from -inf to 0.51500, saving model to best_model.h5\n",
      "150/150 [==============================] - 30s 200ms/step - loss: 66668848.0000 - acc: 0.6683 - val_loss: 265219360.0000 - val_acc: 0.5150\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 12016654.0000 - acc: 0.5103\n",
      "Epoch 00002: val_acc improved from 0.51500 to 0.53583, saving model to best_model.h5\n",
      "150/150 [==============================] - 30s 202ms/step - loss: 12016654.0000 - acc: 0.5103 - val_loss: 33690.1992 - val_acc: 0.5358\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 463177.4375 - acc: 0.4893\n",
      "Epoch 00003: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 463177.4375 - acc: 0.4893 - val_loss: 170523.6875 - val_acc: 0.5200\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 453162.8125 - acc: 0.4959\n",
      "Epoch 00004: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 30s 198ms/step - loss: 453162.8125 - acc: 0.4959 - val_loss: 297286.4688 - val_acc: 0.4800\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 301408.9062 - acc: 0.4893\n",
      "Epoch 00005: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 31s 204ms/step - loss: 301408.9062 - acc: 0.4893 - val_loss: 224010.7656 - val_acc: 0.5117\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 184205.0312 - acc: 0.5009\n",
      "Epoch 00006: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 27s 181ms/step - loss: 184205.0312 - acc: 0.5009 - val_loss: 138356.3750 - val_acc: 0.5225\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 103091.2969 - acc: 0.5047\n",
      "Epoch 00007: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 30s 201ms/step - loss: 103091.2969 - acc: 0.5047 - val_loss: 54062.6758 - val_acc: 0.5175\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 71462.3516 - acc: 0.5009\n",
      "Epoch 00008: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 30s 199ms/step - loss: 71462.3516 - acc: 0.5009 - val_loss: 22554.3359 - val_acc: 0.5133\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 17496.2910 - acc: 0.4959\n",
      "Epoch 00009: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 17496.2910 - acc: 0.4959 - val_loss: 13662.6562 - val_acc: 0.4908\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 18119.6973 - acc: 0.5009\n",
      "Epoch 00010: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 18119.6973 - acc: 0.5009 - val_loss: 353.9646 - val_acc: 0.5358\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 8175.0620 - acc: 0.4970\n",
      "Epoch 00011: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 30s 198ms/step - loss: 8175.0620 - acc: 0.4970 - val_loss: 1372.0026 - val_acc: 0.4867\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 655.6761 - acc: 0.5003\n",
      "Epoch 00012: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 33s 220ms/step - loss: 655.6761 - acc: 0.5003 - val_loss: 39.2662 - val_acc: 0.5117\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 289.1809 - acc: 0.4991\n",
      "Epoch 00013: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 34s 225ms/step - loss: 289.1809 - acc: 0.4991 - val_loss: 737.4274 - val_acc: 0.4667\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1051.8503 - acc: 0.4941\n",
      "Epoch 00014: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 26s 172ms/step - loss: 1051.8503 - acc: 0.4941 - val_loss: 4248.9751 - val_acc: 0.4817\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1959.5205 - acc: 0.5053\n",
      "Epoch 00015: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 1959.5205 - acc: 0.5053 - val_loss: 1004.0828 - val_acc: 0.4517\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1213.0403 - acc: 0.4868\n",
      "Epoch 00016: val_acc did not improve from 0.53583\n",
      "150/150 [==============================] - 26s 176ms/step - loss: 1213.0403 - acc: 0.4868 - val_loss: 399.5817 - val_acc: 0.5083\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 89033.4375 - acc: 0.5078\n",
      "Epoch 00017: val_acc improved from 0.53583 to 0.54000, saving model to best_model.h5\n",
      "150/150 [==============================] - 30s 200ms/step - loss: 89033.4375 - acc: 0.5078 - val_loss: 4629.0073 - val_acc: 0.5400\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 581702.8750 - acc: 0.5020\n",
      "Epoch 00018: val_acc did not improve from 0.54000\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 581702.8750 - acc: 0.5020 - val_loss: 4078.3359 - val_acc: 0.4908\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2699.8215 - acc: 0.4999\n",
      "Epoch 00019: val_acc did not improve from 0.54000\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 2699.8215 - acc: 0.4999 - val_loss: 3891.2791 - val_acc: 0.5083\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1915.2992 - acc: 0.5016\n",
      "Epoch 00020: val_acc did not improve from 0.54000\n",
      "150/150 [==============================] - 30s 197ms/step - loss: 1915.2992 - acc: 0.5016 - val_loss: 1584.5137 - val_acc: 0.5083\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 3371.1221 - acc: 0.4997\n",
      "Epoch 00021: val_acc did not improve from 0.54000\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 3371.1221 - acc: 0.4997 - val_loss: 1762.1650 - val_acc: 0.4892\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1129.2626 - acc: 0.5153\n",
      "Epoch 00022: val_acc did not improve from 0.54000\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 1129.2626 - acc: 0.5153 - val_loss: 206.4383 - val_acc: 0.5083\n",
      "Epoch 00022: early stopping\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 5000.9048 - acc: 0.5103\n",
      "테스트 정확도: 0.5103\n",
      "\u0001D-CNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.5508 - acc: 0.7292\n",
      "Epoch 00001: val_acc improved from -inf to 0.79167, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 18ms/step - loss: 0.5480 - acc: 0.7313 - val_loss: 0.4667 - val_acc: 0.7917\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/150 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.8593\n",
      "Epoch 00002: val_acc improved from 0.79167 to 0.79583, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3556 - acc: 0.8597 - val_loss: 0.4637 - val_acc: 0.7958\n",
      "Epoch 3/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9044\n",
      "Epoch 00003: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.2601 - acc: 0.9039 - val_loss: 0.5305 - val_acc: 0.7842\n",
      "Epoch 4/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2017 - acc: 0.9295\n",
      "Epoch 00004: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 5s 33ms/step - loss: 0.2025 - acc: 0.9291 - val_loss: 0.6131 - val_acc: 0.7742\n",
      "Epoch 5/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9452\n",
      "Epoch 00005: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1638 - acc: 0.9443 - val_loss: 0.6481 - val_acc: 0.7717\n",
      "Epoch 6/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9527\n",
      "Epoch 00006: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1321 - acc: 0.9531 - val_loss: 0.6881 - val_acc: 0.7717\n",
      "Epoch 7/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9587\n",
      "Epoch 00007: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.1075 - acc: 0.9589 - val_loss: 0.7280 - val_acc: 0.7625\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9599- ETA: 0s - loss: 0.0857 - ac\n",
      "Epoch 00008: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 3s 22ms/step - loss: 0.0909 - acc: 0.9600 - val_loss: 0.8189 - val_acc: 0.7558\n",
      "Epoch 9/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9635- ETA: 2s - loss: 0.0747 - acc: 0.965 - ETA\n",
      "Epoch 00009: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 4s 25ms/step - loss: 0.0743 - acc: 0.9633 - val_loss: 0.9553 - val_acc: 0.7550\n",
      "Epoch 10/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9653- ETA: 0s - loss: 0.0607 - acc: 0.9\n",
      "Epoch 00010: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.0621 - acc: 0.9650 - val_loss: 0.9815 - val_acc: 0.7617\n",
      "Epoch 11/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9704\n",
      "Epoch 00011: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.0536 - acc: 0.9706 - val_loss: 1.1366 - val_acc: 0.7592\n",
      "Epoch 12/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9690\n",
      "Epoch 00012: val_acc did not improve from 0.79583\n",
      "150/150 [==============================] - 3s 22ms/step - loss: 0.0471 - acc: 0.9691 - val_loss: 1.3244 - val_acc: 0.7575\n",
      "Epoch 00012: early stopping\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.7994\n",
      "테스트 정확도: 0.7994\n",
      "token_okt2 방식 진행합니다.\n",
      "\n",
      "X_train, y_Train, X_test, y_test (5997,) (5997,) (1999,) (1999,)\n",
      "\n",
      "단어 집합(vocabulary)의 크기 : 6663\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 3172\n",
      "단어 집합에서 희귀 단어의 비율: 47.60618340087048\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.521674673204943\n",
      "\n",
      "vocab size : 3493\n",
      "\n",
      "리뷰의 최대 길이 : 57\n",
      "리뷰의 평균 길이 : 11.697682174420544\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbeUlEQVR4nO3dfZRdVZ3m8e9DwOALNkSKrJgEK4xpW1B5MaLdMg4YlSiOwZkGwyzGtKY7M91pQdu3pO0W2jWZjkuHobunUeNrlvLS8QXJiCPGCI2MSAiQFhJgEU2EmAyJiPJiG0185o+z63qpVCWnkpx7q249n7Xuuufsu8+5v00W91f77HP2lm0iIiIADut2ABERMXokKUREREuSQkREtCQpRERES5JCRES0HN7tAA7Gscce6/7+/m6HERExptxxxx0/sd031GdjOin09/ezbt26bocRETGmSPrRcJ/l8lFERLQkKUREREuSQkREtDSaFCS9S9IGSfdIulrSkZImSVot6YHyfkxb/SWSNkm6X9LZTcYWERF7aywpSJoKXATMsv0iYAIwD1gMrLE9E1hT9pF0Yvn8JGAOcIWkCU3FFxERe2v68tHhwNMlHQ48A9gGzAVWlM9XAOeW7bnANbZ32d4MbAJObzi+iIho01hSsP1j4KPAg8B24Oe2vwlMtr291NkOHFcOmQo81HaKraXsKSQtlLRO0rqdO3c2FX5ExLjU5OWjY6j++p8BPBd4pqQL93XIEGV7zette7ntWbZn9fUN+exFREQcoCYvH70G2Gx7p+1fA18B/gB4WNIUgPK+o9TfCkxvO34a1eWmiIjokCafaH4QeIWkZwD/CswG1gFPAvOBZeX9ulJ/FXCVpMuoehYzgbUNxte4/sXXD1m+Zdk5HY4kIqKexpKC7dskfQm4E9gN3AUsB54FrJS0gCpxnFfqb5C0EthY6i+yvaep+CIiYm+Nzn1k+xLgkkHFu6h6DUPVXwosbTKmiIgYXp5ojoiIliSFiIhoSVKIiIiWJIWIiGhJUoiIiJYkhYiIaElSiIiIliSFiIhoSVKIiIiWJIWIiGhJUoiIiJYkhYiIaElSiIiIliSFiIhoSVKIiIiWJIWIiGhJUoiIiJbGkoKkF0ha3/Z6TNI7JU2StFrSA+X9mLZjlkjaJOl+SWc3FVtERAytyTWa7wdOAZA0AfgxcC2wGFhje5mkxWX//ZJOBOYBJwHPBb4l6XfHwjrN/Yuv73YIERGHRKcuH80GfmD7R8BcYEUpXwGcW7bnAtfY3mV7M7AJOL1D8UVEBJ1LCvOAq8v2ZNvbAcr7caV8KvBQ2zFbS9lTSFooaZ2kdTt37mww5IiI8afxpCDpacCbgC/ur+oQZd6rwF5ue5btWX19fYcixIiIKDrRU3g9cKfth8v+w5KmAJT3HaV8KzC97bhpwLYOxBcREUUnksIF/PbSEcAqYH7Zng9c11Y+T9JESTOAmcDaDsQXERFFY3cfAUh6BvBa4L+0FS8DVkpaADwInAdge4OklcBGYDewaCzceRQR0UsaTQq2fwE8Z1DZI1R3Iw1VfymwtMmYIiJieHmiOSIiWpIUIiKiJUkhIiJakhQiIqIlSSEiIlqSFCIioiVJISIiWpIUIiKiJUkhIiJakhQiIqIlSSEiIlqSFCIioiVJISIiWpIUIiKiJUkhIiJakhQiIqIlSSEiIloaTQqSjpb0JUn3SbpX0u9LmiRptaQHyvsxbfWXSNok6X5JZzcZW0RE7K3pnsLfAd+w/XvAycC9wGJgje2ZwJqyj6QTgXnAScAc4ApJExqOLyIi2jSWFCQ9G3gV8GkA27+y/TNgLrCiVFsBnFu25wLX2N5lezOwCTi9qfgiImJvhzd47hOAncBnJZ0M3AFcDEy2vR3A9nZJx5X6U4HvtR2/tZT1nP7F1w9ZvmXZOR2OJCLiqZq8fHQ4cBrwMdunAk9SLhUNQ0OUea9K0kJJ6ySt27lz56GJNCIigGaTwlZgq+3byv6XqJLEw5KmAJT3HW31p7cdPw3YNviktpfbnmV7Vl9fX2PBR0SMR/tNCpLOk3RU2f4rSV+RdNr+jrP9/4CHJL2gFM0GNgKrgPmlbD5wXdleBcyTNFHSDGAmsHZErYmIiINSZ0zhr21/UdIZwNnAR4GPAS+vcew7gCslPQ34IfA2qkS0UtIC4EHgPADbGyStpEocu4FFtveMtEEREXHg6iSFgR/mc6jGB66TdGmdk9teD8wa4qPZw9RfCiytc+6IiDj06owp/FjSJ4Dzga9LmljzuIiIGGPq/LifD9wAzCnPGUwC3ttoVBER0RX7TQq2f0F1h9AZpWg38ECTQUVERHfUufvoEuD9wJJSdATwhSaDioiI7qhz+ejNwJuoHj7D9jbgqCaDioiI7qiTFH5l25SniyU9s9mQIiKiW+okhZXl7qOjJf0J8C3gk82GFRER3bDf5xRsf1TSa4HHgBcAH7S9uvHIIiKi42rNklqSQBJBRESPGzYpSHqcIWYppZrN1Laf3VhUERHRFcMmBdu5wygiYpypdfmozIp6BlXP4RbbdzUaVUREdMV+k4KkD1LNZPqVUvQ5SV+0/d8ajSz2Kyu4RcShVqencAFwqu1fAkhaBtwJJClERPSYOs8pbAGObNufCPygkWgiIqKr6vQUdgEbJK2mGlN4LXCLpL8HsH1Rg/FFREQH1UkK15bXgJuaCSUiIrqtzhPNKzoRSEREdF+dqbPfKOkuST+V9JikxyU9VufkkrZIulvSeknrStkkSaslPVDej2mrv0TSJkn3Szr7wJsVEREHos5A8+XAfOA5tp9t+6gRPs18lu1TbA+s1bwYWGN7JrCm7CPpRGAecBIwB7hC0oQRfE9ERBykOknhIeCeMn32oTAXGLgktQI4t638Gtu7bG8GNgGnH6LvjIiIGuoMNL8P+Lqkf6a6EwkA25fVONbANyUZ+ITt5cBk29vLObZLOq7UnQp8r+3YraXsKSQtBBYCHH/88TVCiIiIuuokhaXAE1TPKjxthOd/pe1t5Yd/taT79lFXQ5Tt1TspiWU5wKxZsw5V7yUiIqiXFCbZft2BnLws3YntHZKupboc9LCkKaWXMAXYUapvBaa3HT4N2HYg3xsREQemzpjCtySNOClIeqakowa2gdcB9wCrqAauKe/Xle1VwDxJEyXNAGYCa0f6vRERceDq9BQWAe+TtAv4NfXXU5gMXCtp4Huusv0NSbdTLfG5AHiQarI9bG+QtBLYCOwGFtnecyCNioiIA1Pn4bUDWlfB9g+Bk4cofwSYPcwxS6nGMEal4WYljYjoFXXXUziG6nJOa2I82zc3FVRERHRHnfUU/hi4mGrgdz3wCuBW4NXNhjb+ZH2EiOi2OgPNFwMvA35k+yzgVGBno1FFRERX1EkKv2xbYGei7fuAFzQbVkREdEOdMYWtko4Gvkr1ANqj5PmBiIieVOfuozeXzUsl3Qj8DvCNRqOKiIiuqDN19r+RNHFgF+gHntFkUBER0R11xhS+DOyR9Hzg08AM4KpGo4qIiK6okxR+Y3s38GbgctvvAqY0G1ZERHRDnaTwa0kXUM1T9LVSdkRzIUVERLfUSQpvA34fWGp7c5ms7gvNhhUREd1Q5+6jjcBFbfubgWVNBhUREd1Rp6cQERHjRJJCRES0DJsUJH2+vF/cuXAiIqKb9tVTeKmk5wFvl3SMpEntr04FGBERnbOvgeaPU01ncQJwB9XTzANcyiMioocM21Ow/fe2Xwh8xvYJtme0vWonBEkTJN0l6Wtlf5Kk1ZIeKO/HtNVdImmTpPslnX1QLYuIiBHb70Cz7T+VdLKkPy+vl4zwOy4G7m3bXwyssT0TWFP2kXQiMA84CZgDXCFpwgi/KyIiDkKdCfEuAq4EjiuvKyW9o87JJU0DzgE+1VY8F1hRtlcA57aVX2N7V3kWYhNwep3viYiIQ6POegp/DLzc9pMAkj5MtRznP9Q49nLgfcBRbWWTbW8HsL1d0nGlfCrwvbZ6W0vZU0haCCwEOP7442uEEBERddV5TkHAnrb9PTx10Hnog6Q3Ajts31EzlqHO6b0K7OW2Z9me1dfXV/PUERFRR52ewmeB2yRdW/bPpZpCe39eCbxJ0huAI4FnS/oC8LCkKaWXMAXYUepvBaa3HT+NrPAWEdFRdQaaL6OaFO+nwKPA22xfXuO4Jban2e6nGkD+tu0LgVVUM65S3q8r26uAeZImlkn3ZgJrR9ieiIg4CHV6Cti+E7jzEH3nMmClpAXAg8B55Ts2SFoJbAR2A4ts7xn+NBERcajVSgoHy/ZNwE1l+xFg9jD1lgJLOxFTRETsLRPiRUREyz6TQnka+VudCiYiIrprn0mhXNP/haTf6VA8ERHRRXXGFH4J3C1pNfDkQKHti4Y/JCIixqI6SeH68oqIiB5XZ43mFZKeDhxv+/4OxBSD9C9OTo6IzqgzId6/B9ZTra2ApFMkrWo6sIiI6Lw6t6ReSjVb6c8AbK8HZjQYU0REdEmdpLDb9s8Hle01UV1ERIx9dQaa75H0n4AJkmYCFwHfbTasiIjohjo9hXdQrYa2C7gaeAx4Z5NBRUREd9S5++gXwAfK4jq2/XjzYUVERDfUufvoZZLuBr5P9RDbv0h6afOhRUREp9UZU/g08Ge2vwMg6QyqhXde0mRgERHReXXGFB4fSAgAtm8BcgkpIqIHDdtTkHRa2Vwr6RNUg8wG3kJZGyEiInrLvi4f/Y9B+5e0bec5hYiIHjRsUrB91sGcWNKRwM3AxPI9X7J9iaRJwD8B/cAW4Hzbj5ZjlgALgD3ARbZvOJgYIiJiZPY70CzpaOCtVD/irfo1ps7eBbza9hOSjgBukfR/gP8ArLG9TNJiYDHwfkknAvOonol4LvAtSb+bdZojIjqnzt1HXwe+B9wN/KbuiW0beKLsHlFeBuYCZ5byFVTjE+8v5dfY3gVslrSJas6lW+t+Z0REHJw6SeFI239xICeXNAG4A3g+8I+2b5M02fZ2ANvbJR1Xqk+lSj4DtpaywedcCCwEOP744w8krIiIGEadW1I/L+lPJE2RNGngVefktvfYPgWYBpwu6UX7qK6hTjHEOZfbnmV7Vl9fX50wIiKipjo9hV8BHwE+wG9/pA2cUPdLbP9M0k3AHOBhSVNKL2EKsKNU2wpMbztsGrCt7ndERMTBq9NT+Avg+bb7bc8or/0mBEl9ZZCasnLba4D7gFXA/FJtPnBd2V4FzJM0UdIMYCawdmTNiYiIg1Gnp7AB+MUBnHsKsKKMKxwGrLT9NUm3AislLQAeBM4DsL1B0kpgI7AbWJQ7jyIiOqtOUtgDrJd0I9VtpsD+b0m1/X3g1CHKHwFmD3PMUmBpjZgiIqIBdZLCV8srIiJ6XJ31FFZ0IpCIiOi+Ok80b2boW0Nr330UERFjQ53LR7Pato+kGhiu9ZxCRESMLfu9JdX2I22vH9u+HHh1B2KLiIgOq3P56LS23cOoeg5HNRZRRER0TZ3LR+3rKuymTHfdSDQREdFVde4+Oqh1FSIiYuyoc/loIvAf2Xs9hQ81F1ZERHRDnctH1wE/p5oCe9d+6kZExBhWJylMsz2n8UgiIqLr6syS+l1JL248koiI6Lo6PYUzgD8qTzbvoloMx7Zf0mhkERHRcXWSwusbjyIiIkaFOrek/qgTgURERPfVGVOIiIhxIkkhIiJaGksKkqZLulHSvZI2SLq4lE+StFrSA+X9mLZjlkjaJOl+SWc3FVtERAytyZ7CbuDdtl8IvAJYJOlEYDGwxvZMYE3Zp3w2DzgJmANcUdZ3joiIDmksKdjebvvOsv04cC8wFZgLDKzmtgI4t2zPBa6xvcv2ZmATcHpT8UVExN46MqYgqR84FbgNmGx7O1SJAziuVJsKPNR22NZSNvhcCyWtk7Ru586dTYYdETHuNJ4UJD0L+DLwTtuP7avqEGVDLQO63PYs27P6+voOVZgREUHDSUHSEVQJ4UrbXynFD0uaUj6fAuwo5VuB6W2HTwO2NRlfREQ8VZN3Hwn4NHCv7cvaPloFzC/b86lmYR0onydpoqQZwExgbVPxRUTE3upMc3GgXgn8Z+BuSetL2V8Cy4CVkhYADwLnAdjeIGklsJHqzqVFtvc0GF9ERAzSWFKwfQtDjxMAzB7mmKXA0qZiioiIfWuypxBd0r/4+iHLtyw7p8ORRMRYk2kuIiKiJUkhIiJakhQiIqIlSSEiIlqSFCIioiVJISIiWpIUIiKiJc8pDGG4+/wjInpdegoREdGSpBARES1JChER0ZIxhXFkX2Ml3ZoXKfM0RYwu6SlERERLegoB5C/2iKikpxARES1JChER0dLY5SNJnwHeCOyw/aJSNgn4J6Af2AKcb/vR8tkSYAGwB7jI9g1NxRb15bJSxPjSZE/hc8CcQWWLgTW2ZwJryj6STgTmASeVY66QNKHB2CIiYghNrtF8s6T+QcVzgTPL9grgJuD9pfwa27uAzZI2AacDtzYVXxyc9CAielOnxxQm294OUN6PK+VTgYfa6m0tZRER0UGjZaBZQ5R5yIrSQknrJK3buXNnw2FFRIwvnU4KD0uaAlDed5TyrcD0tnrTgG1DncD2ctuzbM/q6+trNNiIiPGm0w+vrQLmA8vK+3Vt5VdJugx4LjATWNvh2KJBmY587BmN06JE85q8JfVqqkHlYyVtBS6hSgYrJS0AHgTOA7C9QdJKYCOwG1hke09TsUVExNCavPvogmE+mj1M/aXA0qbiic5IjyBibBstA80RETEKJClERERLkkJERLRk6uyIg5Snu6OXpKcQEREt47qnkDtlRq/89R3RHeM6KcTYM9JEniQSMTK5fBQRES1JChER0ZLLR9HTMjYRMTJJChHj3KG84SJJeOxLUoioaaQ/nr38A5k793pXkkKMS/lRixhakkJEj+nlHko0L0khosO69aOd3lHUkaQQMUr08o92ei9jR5JCRHRNksXok4fXIiKiZdT1FCTNAf4OmAB8yvayLocUER12qOa4Sk9k5EZVUpA0AfhH4LXAVuB2Satsb+xuZBExmvXyeEynjaqkAJwObLL9QwBJ1wBzgSSFiGhcJ2bhHe29l9GWFKYCD7XtbwVe3l5B0kJgYdl9QtL9Nc57LPCTQxLh6NKr7YLebVuvtgvGUNv04RFVH7ZdIzzPPh3Kc9XwvOE+GG1JQUOU+Sk79nJg+YhOKq2zPetgAhuNerVd0Ltt69V2Qe+2rVfbNZzRdvfRVmB62/40YFuXYomIGHdGW1K4HZgpaYakpwHzgFVdjikiYtwYVZePbO+W9OfADVS3pH7G9oZDcOoRXW4aQ3q1XdC7bevVdkHvtq1X2zUk2d5/rYiIGBdG2+WjiIjooiSFiIho6fmkIGmOpPslbZK0uNvxHChJn5G0Q9I9bWWTJK2W9EB5P6abMR4ISdMl3SjpXkkbJF1cynuhbUdKWivpX0rb/qaUj/m2QTUDgaS7JH2t7I/5dknaIuluSeslrStlY75dI9HTSaFt2ozXAycCF0g6sbtRHbDPAXMGlS0G1tieCawp+2PNbuDdtl8IvAJYVP6NeqFtu4BX2z4ZOAWYI+kV9EbbAC4G7m3b75V2nWX7lLZnE3qlXbX0dFKgbdoM278CBqbNGHNs3wz8dFDxXGBF2V4BnNvRoA4B29tt31m2H6f6kZlKb7TNtp8ou0eUl+mBtkmaBpwDfKqteMy3axi92q4h9XpSGGrajKldiqUJk21vh+rHFTiuy/EcFEn9wKnAbfRI28ollvXADmC17V5p2+XA+4DftJX1QrsMfFPSHWVKHeiNdtU2qp5TaMB+p82I0UHSs4AvA++0/Zg01D/d2GN7D3CKpKOBayW9qNsxHSxJbwR22L5D0pndjucQe6XtbZKOA1ZLuq/bAXVar/cUen3ajIclTQEo7zu6HM8BkXQEVUK40vZXSnFPtG2A7Z8BN1GNC431tr0SeJOkLVSXZF8t6QuM/XZhe1t53wFcS3UJesy3ayR6PSn0+rQZq4D5ZXs+cF0XYzkgqroEnwbutX1Z20e90La+0kNA0tOB1wD3McbbZnuJ7Wm2+6n+n/q27QsZ4+2S9ExJRw1sA68D7mGMt2ukev6JZklvoLr+OTBtxtIuh3RAJF0NnEk1je/DwCXAV4GVwPHAg8B5tgcPRo9qks4AvgPczW+vT/8l1bjCWG/bS6gGJidQ/QG20vaHJD2HMd62AeXy0Xtsv3Gst0vSCVS9A6gurV9le+lYb9dI9XxSiIiI+nr98lFERIxAkkJERLQkKUREREuSQkREtCQpRERES5JCjBmSnth/rRGf85Ry2/LA/qWS3nMQ5zuvzPh646GJ8IDj2CLp2G7GEGNTkkKMd6cAb9hvrfoWAH9m+6xDeM6IjklSiDFJ0nsl3S7p+23rFPSXv9I/WdYv+GZ5khhJLyt1b5X0EUn3lKfcPwS8pcyf/5Zy+hMl3STph5IuGub7Lyjz7t8j6cOl7IPAGcDHJX1kUP0pkm4u33OPpH9byj8maV37egulfIuk/17iXSfpNEk3SPqBpP9a6pxZznmtpI2SPi5pr/+nJV2oal2H9ZI+USbpmyDpcyWWuyW96yD/SaJX2M4rrzHxAp4o76+jWkxdVH/YfA14FdBPtT7DKaXeSuDCsn0P8AdlexlwT9n+I+B/tX3HpcB3gYlUT48/AhwxKI7nUj3Z2kf15Ou3gXPLZzcBs4aI/d3AB8r2BOCosj2prewm4CVlfwvwp2X7fwLfB44q37mjlJ8J/BI4oRy/GvjDtuOPBV4I/O+BNgBXAG8FXko1a+tAfEd3+983r9HxSk8hxqLXldddwJ3A7wEzy2ebba8v23cA/WX+oaNsf7eUX7Wf819ve5ftn1BNfjZ50OcvA26yvdP2buBKqqS0L7cDb5N0KfBiV2tHAJwv6c7SlpOoFoMaMDBP193AbbYft70T+OXAnErAWlfrhewBrqbqqbSbTZUAbi9TeM+mSiI/BE6Q9A+S5gCP7Sf+GCd6fers6E0C/tb2J55SWK3HsKutaA/wdIaeQn1fBp9j8P8nI57X2/bNkl5FtTDN58vlpe8A7wFeZvtRSZ8Djhwijt8Miuk3bTENnqdm8L6AFbaXDI5J0snA2cAi4Hzg7SNtV/Se9BRiLLoBeHtZgwFJU8v890Oy/SjwuKqlMKGa2XPA41SXZUbiNuDfSTpW1ZKvFwD/vK8DJD2P6rLPJ6lmhT0NeDbwJPBzSZOplo0dqdPLLMCHAW8Bbhn0+RrgDwf++6hab/h55c6kw2x/GfjrEk9Eegox9tj+pqQXArdWM2/zBHAh1V/1w1kAfFLSk1TX7n9eym8EFpdLK39b8/u3S1pSjhXwddv7m075TOC9kn5d4n2r7c2S7gI2UF3O+b91vn+QW6nGSF4M3MxvZ/kciHWjpL+iWk3sMODXVD2DfwU+2zYwvVdPIsanzJIa44KkZ7mslyxpMTDF9sVdDuugtE9b3e1YonekpxDjxTnlr/vDgR9R3XUUEYOkpxARES0ZaI6IiJYkhYiIaElSiIiIliSFiIhoSVKIiIiW/w8L6kNkPOCxOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.98332499583125\n",
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 100.0\n",
      "(5997, 55) (1999, 55)\n",
      "\n",
      "DNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.5469\n",
      "Epoch 00001: val_acc improved from -inf to 0.55476, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6832 - acc: 0.5485 - val_loss: 0.6778 - val_acc: 0.5548\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6723 - acc: 0.5626\n",
      "Epoch 00002: val_acc improved from 0.55476 to 0.55495, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6723 - acc: 0.5626 - val_loss: 0.6780 - val_acc: 0.5550\n",
      "Epoch 3/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6695 - acc: 0.5643\n",
      "Epoch 00003: val_acc improved from 0.55495 to 0.55495, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6694 - acc: 0.5638 - val_loss: 0.6803 - val_acc: 0.5550\n",
      "Epoch 4/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6684 - acc: 0.5633\n",
      "Epoch 00004: val_acc improved from 0.55495 to 0.55502, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6684 - acc: 0.5643 - val_loss: 0.6802 - val_acc: 0.5550\n",
      "Epoch 5/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6681 - acc: 0.5571\n",
      "Epoch 00005: val_acc did not improve from 0.55502\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6682 - acc: 0.5580 - val_loss: 0.6809 - val_acc: 0.5550\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6670 - acc: 0.5647\n",
      "Epoch 00006: val_acc improved from 0.55502 to 0.55520, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 18ms/step - loss: 0.6670 - acc: 0.5647 - val_loss: 0.6851 - val_acc: 0.5552\n",
      "Epoch 7/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6668 - acc: 0.5664- ETA: 1s - \n",
      "Epoch 00007: val_acc did not improve from 0.55520\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.6669 - acc: 0.5650 - val_loss: 0.6831 - val_acc: 0.5550\n",
      "Epoch 8/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6663 - acc: 0.5650\n",
      "Epoch 00008: val_acc did not improve from 0.55520\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6663 - acc: 0.5651 - val_loss: 0.6845 - val_acc: 0.5551\n",
      "Epoch 9/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6660 - acc: 0.5656\n",
      "Epoch 00009: val_acc improved from 0.55520 to 0.55527, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.6661 - acc: 0.5650 - val_loss: 0.6866 - val_acc: 0.5553\n",
      "Epoch 10/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6662 - acc: 0.5657\n",
      "Epoch 00010: val_acc did not improve from 0.55527\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6662 - acc: 0.5648 - val_loss: 0.6901 - val_acc: 0.5552\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6660 - acc: 0.5649\n",
      "Epoch 00011: val_acc did not improve from 0.55527\n",
      "150/150 [==============================] - 4s 23ms/step - loss: 0.6660 - acc: 0.5649 - val_loss: 0.6893 - val_acc: 0.5553\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6850 - acc: 0.5376\n",
      "테스트 정확도: 0.5376\n",
      "\n",
      "LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5295 - acc: 0.7375\n",
      "Epoch 00001: val_acc improved from -inf to 0.79333, saving model to best_model.h5\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 0.5295 - acc: 0.7375 - val_loss: 0.4660 - val_acc: 0.7933\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.8622\n",
      "Epoch 00002: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 0.3449 - acc: 0.8622 - val_loss: 0.4813 - val_acc: 0.7883\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2811 - acc: 0.8887\n",
      "Epoch 00003: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.2811 - acc: 0.8887 - val_loss: 0.5170 - val_acc: 0.7775\n",
      "Epoch 4/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9094\n",
      "Epoch 00004: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.2385 - acc: 0.9097 - val_loss: 0.5757 - val_acc: 0.7783\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.9206\n",
      "Epoch 00005: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 10s 63ms/step - loss: 0.2082 - acc: 0.9206 - val_loss: 0.6566 - val_acc: 0.7767\n",
      "Epoch 6/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9287\n",
      "Epoch 00006: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 6s 39ms/step - loss: 0.1831 - acc: 0.9287 - val_loss: 0.6856 - val_acc: 0.7725\n",
      "Epoch 7/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9325\n",
      "Epoch 00007: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.1640 - acc: 0.9325 - val_loss: 0.7250 - val_acc: 0.7675\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1536 - acc: 0.9354\n",
      "Epoch 00008: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 63ms/step - loss: 0.1536 - acc: 0.9354 - val_loss: 0.7852 - val_acc: 0.7583\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1296 - acc: 0.9427- ETA: 1s -\n",
      "Epoch 00009: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.1296 - acc: 0.9427 - val_loss: 0.8298 - val_acc: 0.7533\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1257 - acc: 0.9429\n",
      "Epoch 00010: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.1257 - acc: 0.9429 - val_loss: 0.9740 - val_acc: 0.7625\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1165 - acc: 0.9425\n",
      "Epoch 00011: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.1165 - acc: 0.9425 - val_loss: 0.9504 - val_acc: 0.7542\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4640 - acc: 0.7989\n",
      "테스트 정확도: 0.7989\n",
      "\n",
      "LSTM_2layer 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7116 - acc: 0.7050\n",
      "Epoch 00001: val_acc improved from -inf to 0.73500, saving model to best_model.h5\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 0.7116 - acc: 0.7050 - val_loss: 0.5370 - val_acc: 0.7350\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3993 - acc: 0.8101\n",
      "Epoch 00002: val_acc improved from 0.73500 to 0.76917, saving model to best_model.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 1.3993 - acc: 0.8101 - val_loss: 0.5445 - val_acc: 0.7692\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 13.7985 - acc: 0.7811 ETA: 0s - loss: 14.3456 -\n",
      "Epoch 00003: val_acc did not improve from 0.76917\n",
      "150/150 [==============================] - 18s 119ms/step - loss: 13.7985 - acc: 0.7811 - val_loss: 0.7854 - val_acc: 0.7342\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.9780 - acc: 0.8522\n",
      "Epoch 00004: val_acc improved from 0.76917 to 0.78667, saving model to best_model.h5\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.9780 - acc: 0.8522 - val_loss: 0.5315 - val_acc: 0.7867\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1352.8962 - acc: 0.7573\n",
      "Epoch 00005: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 1352.8962 - acc: 0.7573 - val_loss: 0.5985 - val_acc: 0.7492\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6154 - acc: 0.8491\n",
      "Epoch 00006: val_acc improved from 0.78667 to 0.80250, saving model to best_model.h5\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 0.6154 - acc: 0.8491 - val_loss: 0.5847 - val_acc: 0.8025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 81.9634 - acc: 0.8061\n",
      "Epoch 00007: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 17s 112ms/step - loss: 81.9634 - acc: 0.8061 - val_loss: 0.5809 - val_acc: 0.7608\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4402 - acc: 0.8582\n",
      "Epoch 00008: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 19s 125ms/step - loss: 0.4402 - acc: 0.8582 - val_loss: 0.7181 - val_acc: 0.7942\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3815 - acc: 0.8741\n",
      "Epoch 00009: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 0.3815 - acc: 0.8741 - val_loss: 0.5892 - val_acc: 0.8017\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3129 - acc: 0.8822\n",
      "Epoch 00010: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 18s 117ms/step - loss: 0.3129 - acc: 0.8822 - val_loss: 0.6456 - val_acc: 0.7992\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2841 - acc: 0.8858\n",
      "Epoch 00011: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 18s 122ms/step - loss: 0.2841 - acc: 0.8858 - val_loss: 0.7200 - val_acc: 0.7925\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3317 - acc: 0.8772\n",
      "Epoch 00012: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.3317 - acc: 0.8772 - val_loss: 0.8476 - val_acc: 0.7808\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3318 - acc: 0.8824\n",
      "Epoch 00013: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 18s 122ms/step - loss: 0.3318 - acc: 0.8824 - val_loss: 0.7595 - val_acc: 0.7825\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2905 - acc: 0.8910\n",
      "Epoch 00014: val_acc did not improve from 0.80250\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.2905 - acc: 0.8910 - val_loss: 1.6460 - val_acc: 0.7800\n",
      "Epoch 00014: early stopping\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 4.3587 - acc: 0.7819\n",
      "테스트 정확도: 0.7819\n",
      "\n",
      "Bi-LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6127 - acc: 0.7194\n",
      "Epoch 00001: val_acc improved from -inf to 0.77667, saving model to best_model.h5\n",
      "150/150 [==============================] - 18s 117ms/step - loss: 0.6127 - acc: 0.7194 - val_loss: 0.5516 - val_acc: 0.7767\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 22.1719 - acc: 0.7403\n",
      "Epoch 00002: val_acc did not improve from 0.77667\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 22.1719 - acc: 0.7403 - val_loss: 0.5410 - val_acc: 0.7733\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 5.7237 - acc: 0.8170\n",
      "Epoch 00003: val_acc improved from 0.77667 to 0.79000, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 5.7237 - acc: 0.8170 - val_loss: 0.8450 - val_acc: 0.7900\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 29.3300 - acc: 0.8297\n",
      "Epoch 00004: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 29.3300 - acc: 0.8297 - val_loss: 0.4922 - val_acc: 0.7658\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5926 - acc: 0.8647\n",
      "Epoch 00005: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 0.5926 - acc: 0.8647 - val_loss: 1.1136 - val_acc: 0.6742\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3255 - acc: 0.8770- ETA: 0s - loss: 0.3262 - acc\n",
      "Epoch 00006: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 0.3255 - acc: 0.8770 - val_loss: 0.5941 - val_acc: 0.7758\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2717 - acc: 0.8935\n",
      "Epoch 00007: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.2717 - acc: 0.8935 - val_loss: 0.5918 - val_acc: 0.7725\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2986 - acc: 0.8885\n",
      "Epoch 00008: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.2986 - acc: 0.8885 - val_loss: 0.6914 - val_acc: 0.7817\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2653 - acc: 0.8960\n",
      "Epoch 00009: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.2653 - acc: 0.8960 - val_loss: 0.6897 - val_acc: 0.7667\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2834 - acc: 0.9041\n",
      "Epoch 00010: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 0.2834 - acc: 0.9041 - val_loss: 0.6624 - val_acc: 0.7600\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2230 - acc: 0.9077\n",
      "Epoch 00011: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.2230 - acc: 0.9077 - val_loss: 0.8935 - val_acc: 0.7783\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6834 - acc: 0.9106- ETA: 0s - loss: 0.6890 - acc: 0.91\n",
      "Epoch 00012: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.6834 - acc: 0.9106 - val_loss: 2.2287 - val_acc: 0.7608\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1814 - acc: 0.9181\n",
      "Epoch 00013: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 0.1814 - acc: 0.9181 - val_loss: 0.9255 - val_acc: 0.7642\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1867 - acc: 0.9216- ETA: 0s - loss: 0.1857 - acc\n",
      "Epoch 00014: val_acc did not improve from 0.79000\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 0.1867 - acc: 0.9216 - val_loss: 1.8132 - val_acc: 0.7717\n",
      "Epoch 00014: early stopping\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.8870 - acc: 0.7754:\n",
      "테스트 정확도: 0.7754\n",
      "\n",
      "Bi-LSTM 2층 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 404952481792.0000 - acc: 0.6829\n",
      "Epoch 00001: val_acc improved from -inf to 0.78750, saving model to best_model.h5\n",
      "150/150 [==============================] - 32s 212ms/step - loss: 404952481792.0000 - acc: 0.6829 - val_loss: 0.4919 - val_acc: 0.7875\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4806 - acc: 0.8299\n",
      "Epoch 00002: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 32s 211ms/step - loss: 0.4806 - acc: 0.8299 - val_loss: 0.5588 - val_acc: 0.7833\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5767 - acc: 0.8482\n",
      "Epoch 00003: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 30s 200ms/step - loss: 0.5767 - acc: 0.8482 - val_loss: 0.7276 - val_acc: 0.7817\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.4656 - acc: 0.8528\n",
      "Epoch 00004: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 32s 213ms/step - loss: 2.4656 - acc: 0.8528 - val_loss: 0.5076 - val_acc: 0.7800\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.6720 - acc: 0.8639\n",
      "Epoch 00005: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 30s 202ms/step - loss: 2.6720 - acc: 0.8639 - val_loss: 4.7160 - val_acc: 0.7742\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.9280 - acc: 0.8553\n",
      "Epoch 00006: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 2.9280 - acc: 0.8553 - val_loss: 4.9720 - val_acc: 0.7575\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 756.1456 - acc: 0.8647\n",
      "Epoch 00007: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 33s 223ms/step - loss: 756.1456 - acc: 0.8647 - val_loss: 19.9699 - val_acc: 0.7650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1031.4158 - acc: 0.8695\n",
      "Epoch 00008: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 1031.4158 - acc: 0.8695 - val_loss: 43.0523 - val_acc: 0.7633\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2894.2861 - acc: 0.8747\n",
      "Epoch 00009: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 2894.2861 - acc: 0.8747 - val_loss: 72.4161 - val_acc: 0.7592\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 183504.8750 - acc: 0.8624\n",
      "Epoch 00010: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 27s 180ms/step - loss: 183504.8750 - acc: 0.8624 - val_loss: 2491.2185 - val_acc: 0.7175\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1259.1605 - acc: 0.8503\n",
      "Epoch 00011: val_acc did not improve from 0.78750\n",
      "150/150 [==============================] - 27s 179ms/step - loss: 1259.1605 - acc: 0.8503 - val_loss: 1717.2708 - val_acc: 0.7292\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 0.4947 - acc: 0.7819\n",
      "테스트 정확도: 0.7819\n",
      "\u0001D-CNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5371 - acc: 0.7363\n",
      "Epoch 00001: val_acc improved from -inf to 0.78917, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 21ms/step - loss: 0.5371 - acc: 0.7363 - val_loss: 0.4745 - val_acc: 0.7892\n",
      "Epoch 2/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3548 - acc: 0.8633\n",
      "Epoch 00002: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 4s 26ms/step - loss: 0.3549 - acc: 0.8635 - val_loss: 0.4841 - val_acc: 0.7858\n",
      "Epoch 3/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2566 - acc: 0.9100\n",
      "Epoch 00003: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.2566 - acc: 0.9097 - val_loss: 0.5461 - val_acc: 0.7783\n",
      "Epoch 4/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9367\n",
      "Epoch 00004: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.1960 - acc: 0.9366 - val_loss: 0.5739 - val_acc: 0.7583\n",
      "Epoch 5/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9430\n",
      "Epoch 00005: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.1623 - acc: 0.9431 - val_loss: 0.6852 - val_acc: 0.7617\n",
      "Epoch 6/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9522\n",
      "Epoch 00006: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 5s 33ms/step - loss: 0.1342 - acc: 0.9504 - val_loss: 0.7315 - val_acc: 0.7608\n",
      "Epoch 7/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9560\n",
      "Epoch 00007: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.1090 - acc: 0.9556 - val_loss: 0.8379 - val_acc: 0.7617\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9581\n",
      "Epoch 00008: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.0898 - acc: 0.9579 - val_loss: 0.9000 - val_acc: 0.7667\n",
      "Epoch 9/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9611\n",
      "Epoch 00009: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.0735 - acc: 0.9602 - val_loss: 1.0029 - val_acc: 0.7608\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0610 - acc: 0.9637\n",
      "Epoch 00010: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.0610 - acc: 0.9637 - val_loss: 1.0078 - val_acc: 0.7583\n",
      "Epoch 11/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9658\n",
      "Epoch 00011: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 3s 18ms/step - loss: 0.0557 - acc: 0.9656 - val_loss: 1.1607 - val_acc: 0.7517\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4632 - acc: 0.7984\n",
      "테스트 정확도: 0.7984\n",
      "token_mecab1 방식 진행합니다.\n",
      "\n",
      "X_train, y_Train, X_test, y_test (5997,) (5997,) (1999,) (1999,)\n",
      "\n",
      "단어 집합(vocabulary)의 크기 : 7004\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 3452\n",
      "단어 집합에서 희귀 단어의 비율: 49.286122215876645\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.272813462905902\n",
      "\n",
      "vocab size : 3554\n",
      "\n",
      "리뷰의 최대 길이 : 85\n",
      "리뷰의 평균 길이 : 17.58796064699016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 94.83074870768718\n",
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 94.14707353676839\n",
      "(5997, 55) (1999, 55)\n",
      "\n",
      "DNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6777 - acc: 0.5745\n",
      "Epoch 00001: val_acc improved from -inf to 0.57773, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.6773 - acc: 0.5753 - val_loss: 0.6734 - val_acc: 0.5777\n",
      "Epoch 2/30\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.6658 - acc: 0.5873\n",
      "Epoch 00002: val_acc improved from 0.57773 to 0.57802, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6663 - acc: 0.5859 - val_loss: 0.6733 - val_acc: 0.5780\n",
      "Epoch 3/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6637 - acc: 0.5863\n",
      "Epoch 00003: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6636 - acc: 0.5877 - val_loss: 0.6735 - val_acc: 0.5774\n",
      "Epoch 4/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6622 - acc: 0.5882\n",
      "Epoch 00004: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6621 - acc: 0.5881 - val_loss: 0.6772 - val_acc: 0.5772\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6615 - acc: 0.5885\n",
      "Epoch 00005: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6615 - acc: 0.5885 - val_loss: 0.6760 - val_acc: 0.5777\n",
      "Epoch 6/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6610 - acc: 0.5886\n",
      "Epoch 00006: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.6609 - acc: 0.5890 - val_loss: 0.6762 - val_acc: 0.5776\n",
      "Epoch 7/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6608 - acc: 0.5842\n",
      "Epoch 00007: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 3s 17ms/step - loss: 0.6608 - acc: 0.5840 - val_loss: 0.6777 - val_acc: 0.5773\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6602 - acc: 0.5889\n",
      "Epoch 00008: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6602 - acc: 0.5889 - val_loss: 0.6776 - val_acc: 0.5777\n",
      "Epoch 9/30\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.6601 - acc: 0.5897\n",
      "Epoch 00009: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6602 - acc: 0.5891 - val_loss: 0.6808 - val_acc: 0.5776\n",
      "Epoch 10/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6601 - acc: 0.5887\n",
      "Epoch 00010: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.6601 - acc: 0.5891 - val_loss: 0.6845 - val_acc: 0.5777\n",
      "Epoch 11/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6599 - acc: 0.5892\n",
      "Epoch 00011: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6597 - acc: 0.5890 - val_loss: 0.6821 - val_acc: 0.5776\n",
      "Epoch 12/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6599 - acc: 0.5884\n",
      "Epoch 00012: val_acc did not improve from 0.57802\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6597 - acc: 0.5891 - val_loss: 0.6836 - val_acc: 0.5776\n",
      "Epoch 00012: early stopping\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6729 - acc: 0.5650\n",
      "테스트 정확도: 0.5650\n",
      "\n",
      "LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.7412\n",
      "Epoch 00001: val_acc improved from -inf to 0.79083, saving model to best_model.h5\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.5242 - acc: 0.7417 - val_loss: 0.4659 - val_acc: 0.7908\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3632 - acc: 0.8578\n",
      "Epoch 00002: val_acc improved from 0.79083 to 0.79333, saving model to best_model.h5\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.3632 - acc: 0.8578 - val_loss: 0.4998 - val_acc: 0.7933\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2965 - acc: 0.8887\n",
      "Epoch 00003: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 8s 50ms/step - loss: 0.2965 - acc: 0.8887 - val_loss: 0.5216 - val_acc: 0.7867\n",
      "Epoch 4/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9052\n",
      "Epoch 00004: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.2471 - acc: 0.9049 - val_loss: 0.5714 - val_acc: 0.7758\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2141 - acc: 0.9197\n",
      "Epoch 00005: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.2141 - acc: 0.9197 - val_loss: 0.6563 - val_acc: 0.7792\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1868 - acc: 0.9275\n",
      "Epoch 00006: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 6s 39ms/step - loss: 0.1868 - acc: 0.9275 - val_loss: 0.6934 - val_acc: 0.7683\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1634 - acc: 0.9337\n",
      "Epoch 00007: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.1634 - acc: 0.9337 - val_loss: 0.7498 - val_acc: 0.7692\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9354\n",
      "Epoch 00008: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.1437 - acc: 0.9358 - val_loss: 0.7945 - val_acc: 0.7725\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1290 - acc: 0.9425\n",
      "Epoch 00009: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1290 - acc: 0.9425 - val_loss: 0.8431 - val_acc: 0.7642\n",
      "Epoch 10/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9453\n",
      "Epoch 00010: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.1262 - acc: 0.9456 - val_loss: 0.8339 - val_acc: 0.7617\n",
      "Epoch 11/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9467\n",
      "Epoch 00011: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.1237 - acc: 0.9471 - val_loss: 0.9491 - val_acc: 0.7725\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4850 - acc: 0.8064\n",
      "테스트 정확도: 0.8064\n",
      "\n",
      "LSTM_2layer 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.6060 - acc: 0.6833\n",
      "Epoch 00001: val_acc improved from -inf to 0.64500, saving model to best_model.h5\n",
      "150/150 [==============================] - 14s 97ms/step - loss: 3.6060 - acc: 0.6833 - val_loss: 0.6220 - val_acc: 0.6450\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 282.2347 - acc: 0.7330\n",
      "Epoch 00002: val_acc improved from 0.64500 to 0.75833, saving model to best_model.h5\n",
      "150/150 [==============================] - 19s 125ms/step - loss: 282.2347 - acc: 0.7330 - val_loss: 0.5178 - val_acc: 0.7583\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.5512 - acc: 0.8009\n",
      "Epoch 00003: val_acc did not improve from 0.75833\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 4.5512 - acc: 0.8009 - val_loss: 0.5399 - val_acc: 0.7483\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3894 - acc: 0.8459\n",
      "Epoch 00004: val_acc improved from 0.75833 to 0.76500, saving model to best_model.h5\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.3894 - acc: 0.8459 - val_loss: 0.5061 - val_acc: 0.7650\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3222 - acc: 0.8668\n",
      "Epoch 00005: val_acc improved from 0.76500 to 0.76833, saving model to best_model.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.3222 - acc: 0.8668 - val_loss: 0.7114 - val_acc: 0.7683\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2894 - acc: 0.8862\n",
      "Epoch 00006: val_acc improved from 0.76833 to 0.77083, saving model to best_model.h5\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.2894 - acc: 0.8862 - val_loss: 0.5610 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2587 - acc: 0.8999\n",
      "Epoch 00007: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 18s 122ms/step - loss: 0.2587 - acc: 0.8999 - val_loss: 0.5990 - val_acc: 0.7667\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 54210.0430 - acc: 0.8449\n",
      "Epoch 00008: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 54210.0430 - acc: 0.8449 - val_loss: 51.0623 - val_acc: 0.6383\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 6.6590 - acc: 0.7006\n",
      "Epoch 00009: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 6.6590 - acc: 0.7006 - val_loss: 2.3925 - val_acc: 0.6592\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.6679 - acc: 0.7044\n",
      "Epoch 00010: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 1.6679 - acc: 0.7044 - val_loss: 1.3600 - val_acc: 0.6600\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0621 - acc: 0.7027- ETA: 0s - loss: 1.0795 - acc: 0\n",
      "Epoch 00011: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 18s 121ms/step - loss: 1.0621 - acc: 0.7027 - val_loss: 0.6596 - val_acc: 0.6450\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4714 - acc: 0.7782\n",
      "Epoch 00012: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.4714 - acc: 0.7782 - val_loss: 0.6232 - val_acc: 0.6950\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 23542960.0000 - acc: 0.7013\n",
      "Epoch 00013: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 23542960.0000 - acc: 0.7013 - val_loss: 2.0158 - val_acc: 0.7258\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 23.8101 - acc: 0.7724\n",
      "Epoch 00014: val_acc did not improve from 0.77083\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 23.8101 - acc: 0.7724 - val_loss: 6.3993 - val_acc: 0.6067\n",
      "Epoch 00014: early stopping\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.5185 - acc: 0.7899\n",
      "테스트 정확도: 0.7899\n",
      "\n",
      "Bi-LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 41.2094 - acc: 0.6725\n",
      "Epoch 00001: val_acc improved from -inf to 0.58750, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 41.2094 - acc: 0.6725 - val_loss: 0.6060 - val_acc: 0.5875\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2414 - acc: 0.7342\n",
      "Epoch 00002: val_acc improved from 0.58750 to 0.63917, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 83ms/step - loss: 1.2414 - acc: 0.7342 - val_loss: 0.6054 - val_acc: 0.6392\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6255 - acc: 0.7719\n",
      "Epoch 00003: val_acc improved from 0.63917 to 0.73417, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.6255 - acc: 0.7719 - val_loss: 0.5925 - val_acc: 0.7342\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 60.0247 - acc: 0.6954\n",
      "Epoch 00004: val_acc improved from 0.73417 to 0.73583, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 60.0247 - acc: 0.6954 - val_loss: 0.6223 - val_acc: 0.7358\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 33.0528 - acc: 0.7940\n",
      "Epoch 00005: val_acc improved from 0.73583 to 0.78083, saving model to best_model.h5\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 33.0528 - acc: 0.7940 - val_loss: 1.5962 - val_acc: 0.7808\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 8.8988 - acc: 0.7924\n",
      "Epoch 00006: val_acc improved from 0.78083 to 0.78167, saving model to best_model.h5\n",
      "150/150 [==============================] - 12s 79ms/step - loss: 8.8988 - acc: 0.7924 - val_loss: 1.4123 - val_acc: 0.7817\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 29260.9238 - acc: 0.7934\n",
      "Epoch 00007: val_acc did not improve from 0.78167\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 29260.9238 - acc: 0.7934 - val_loss: 0.5515 - val_acc: 0.7583\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4547 - acc: 0.8407\n",
      "Epoch 00008: val_acc did not improve from 0.78167\n",
      "150/150 [==============================] - 17s 116ms/step - loss: 0.4547 - acc: 0.8407 - val_loss: 8.1340 - val_acc: 0.7717\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5749 - acc: 0.8514\n",
      "Epoch 00009: val_acc improved from 0.78167 to 0.78333, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.5749 - acc: 0.8514 - val_loss: 0.4989 - val_acc: 0.7833\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3556 - acc: 0.8612\n",
      "Epoch 00010: val_acc improved from 0.78333 to 0.78417, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 0.3556 - acc: 0.8612 - val_loss: 0.5312 - val_acc: 0.7842\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3173 - acc: 0.8701\n",
      "Epoch 00011: val_acc improved from 0.78417 to 0.78667, saving model to best_model.h5\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 0.3173 - acc: 0.8701 - val_loss: 0.5851 - val_acc: 0.7867\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2930 - acc: 0.8793\n",
      "Epoch 00012: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.2930 - acc: 0.8793 - val_loss: 0.5685 - val_acc: 0.7858\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2675 - acc: 0.8878\n",
      "Epoch 00013: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.2675 - acc: 0.8878 - val_loss: 0.6458 - val_acc: 0.7825\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2540 - acc: 0.8933\n",
      "Epoch 00014: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.2540 - acc: 0.8933 - val_loss: 0.7039 - val_acc: 0.7842\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2368 - acc: 0.8968\n",
      "Epoch 00015: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.2368 - acc: 0.8968 - val_loss: 0.7381 - val_acc: 0.7792\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2259 - acc: 0.9041\n",
      "Epoch 00016: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 0.2259 - acc: 0.9041 - val_loss: 1.0071 - val_acc: 0.7775\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2194 - acc: 0.9085\n",
      "Epoch 00017: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.2194 - acc: 0.9085 - val_loss: 0.6856 - val_acc: 0.7767\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2099 - acc: 0.9135\n",
      "Epoch 00018: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.2099 - acc: 0.9135 - val_loss: 0.8228 - val_acc: 0.7675\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2017 - acc: 0.9154\n",
      "Epoch 00019: val_acc did not improve from 0.78667\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.2017 - acc: 0.9154 - val_loss: 0.8584 - val_acc: 0.7775\n",
      "Epoch 00019: early stopping\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.6061 - acc: 0.7954\n",
      "테스트 정확도: 0.7954\n",
      "\n",
      "Bi-LSTM 2층 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 9.1020 - acc: 0.6702\n",
      "Epoch 00001: val_acc improved from -inf to 0.67000, saving model to best_model.h5\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 9.1020 - acc: 0.6702 - val_loss: 0.6406 - val_acc: 0.6700\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - loss: 2.0608 - acc: 0.6965\n",
      "Epoch 00002: val_acc improved from 0.67000 to 0.71083, saving model to best_model.h5\n",
      "150/150 [==============================] - 29s 190ms/step - loss: 2.0608 - acc: 0.6965 - val_loss: 0.6316 - val_acc: 0.7108\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 10872.6367 - acc: 0.5741\n",
      "Epoch 00003: val_acc did not improve from 0.71083\n",
      "150/150 [==============================] - 26s 172ms/step - loss: 10872.6367 - acc: 0.5741 - val_loss: 0.7096 - val_acc: 0.4925\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7216 - acc: 0.5087\n",
      "Epoch 00004: val_acc did not improve from 0.71083\n",
      "150/150 [==============================] - 29s 190ms/step - loss: 0.7216 - acc: 0.5087 - val_loss: 0.7423 - val_acc: 0.4925\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0760 - acc: 0.5266\n",
      "Epoch 00005: val_acc improved from 0.71083 to 0.74917, saving model to best_model.h5\n",
      "150/150 [==============================] - 26s 172ms/step - loss: 1.0760 - acc: 0.5266 - val_loss: 0.6505 - val_acc: 0.7492\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6173 - acc: 0.7857\n",
      "Epoch 00006: val_acc improved from 0.74917 to 0.78583, saving model to best_model.h5\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 0.6173 - acc: 0.7857 - val_loss: 590415.4375 - val_acc: 0.7858\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1776531.0000 - acc: 0.5353\n",
      "Epoch 00007: val_acc did not improve from 0.78583\n",
      "150/150 [==============================] - 26s 171ms/step - loss: 1776531.0000 - acc: 0.5353 - val_loss: 0.6907 - val_acc: 0.5075\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6835 - acc: 0.5232\n",
      "Epoch 00008: val_acc did not improve from 0.78583\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 0.6835 - acc: 0.5232 - val_loss: 153.4521 - val_acc: 0.5150\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6882 - acc: 0.7265\n",
      "Epoch 00009: val_acc did not improve from 0.78583\n",
      "150/150 [==============================] - 26s 170ms/step - loss: 0.6882 - acc: 0.7265 - val_loss: 0.6745 - val_acc: 0.5858\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7389 - acc: 0.6573\n",
      "Epoch 00010: val_acc did not improve from 0.78583\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 0.7389 - acc: 0.6573 - val_loss: 0.6798 - val_acc: 0.5850\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 336913.9375 - acc: 0.5977\n",
      "Epoch 00011: val_acc did not improve from 0.78583\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 336913.9375 - acc: 0.5977 - val_loss: 1.5701 - val_acc: 0.7700\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3007 - acc: 0.6333\n",
      "Epoch 00012: val_acc did not improve from 0.78583\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 1.3007 - acc: 0.6333 - val_loss: 36.4014 - val_acc: 0.5650\n",
      "Epoch 00012: early stopping\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 141364.7812 - acc: 0.7869 0s - loss: 169\n",
      "테스트 정확도: 0.7869\n",
      "\u0001D-CNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.5457 - acc: 0.7217\n",
      "Epoch 00001: val_acc improved from -inf to 0.78833, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 22ms/step - loss: 0.5441 - acc: 0.7230 - val_loss: 0.4649 - val_acc: 0.7883\n",
      "Epoch 2/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8538\n",
      "Epoch 00002: val_acc improved from 0.78833 to 0.78917, saving model to best_model.h5\n",
      "150/150 [==============================] - 4s 30ms/step - loss: 0.3636 - acc: 0.8539 - val_loss: 0.4730 - val_acc: 0.7892\n",
      "Epoch 3/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9020\n",
      "Epoch 00003: val_acc improved from 0.78917 to 0.79333, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 19ms/step - loss: 0.2760 - acc: 0.9022 - val_loss: 0.5014 - val_acc: 0.7933\n",
      "Epoch 4/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9266\n",
      "Epoch 00004: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 4s 24ms/step - loss: 0.2107 - acc: 0.9264 - val_loss: 0.5647 - val_acc: 0.7875\n",
      "Epoch 5/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9421\n",
      "Epoch 00005: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 4s 29ms/step - loss: 0.1681 - acc: 0.9420 - val_loss: 0.6217 - val_acc: 0.7783\n",
      "Epoch 6/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9524\n",
      "Epoch 00006: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.1351 - acc: 0.9527 - val_loss: 0.7029 - val_acc: 0.7792\n",
      "Epoch 7/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9588\n",
      "Epoch 00007: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 3s 18ms/step - loss: 0.1191 - acc: 0.9585 - val_loss: 0.7401 - val_acc: 0.7758\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9616\n",
      "Epoch 00008: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 6s 37ms/step - loss: 0.0988 - acc: 0.9614 - val_loss: 0.7776 - val_acc: 0.7733\n",
      "Epoch 9/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9643\n",
      "Epoch 00009: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 3s 17ms/step - loss: 0.0804 - acc: 0.9637 - val_loss: 0.8896 - val_acc: 0.7717\n",
      "Epoch 10/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9664\n",
      "Epoch 00010: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 3s 23ms/step - loss: 0.0679 - acc: 0.9662 - val_loss: 0.9928 - val_acc: 0.7708\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0581 - acc: 0.9652\n",
      "Epoch 00011: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 4s 25ms/step - loss: 0.0581 - acc: 0.9652 - val_loss: 1.0455 - val_acc: 0.7675\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4975 - acc: 0.7979\n",
      "테스트 정확도: 0.7979\n",
      "token_mecab2 방식 진행합니다.\n",
      "\n",
      "X_train, y_Train, X_test, y_test (5997,) (5997,) (1999,) (1999,)\n",
      "\n",
      "단어 집합(vocabulary)의 크기 : 6977\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 3452\n",
      "단어 집합에서 희귀 단어의 비율: 49.47685251540777\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.142118335953155\n",
      "\n",
      "vocab size : 3527\n",
      "\n",
      "리뷰의 최대 길이 : 64\n",
      "리뷰의 평균 길이 : 13.896781724195431\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.78322494580624\n",
      "전체 샘플 중 길이가 55 이하인 샘플의 비율: 99.74987493746873\n",
      "(5997, 55) (1999, 55)\n",
      "\n",
      "DNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6802 - acc: 0.5615\n",
      "Epoch 00001: val_acc improved from -inf to 0.56427, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.6802 - acc: 0.5617 - val_loss: 0.6753 - val_acc: 0.5643\n",
      "Epoch 2/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.6697 - acc: 0.5724\n",
      "Epoch 00002: val_acc improved from 0.56427 to 0.56429, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6697 - acc: 0.5723 - val_loss: 0.6752 - val_acc: 0.5643\n",
      "Epoch 3/30\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.6667 - acc: 0.5744\n",
      "Epoch 00003: val_acc improved from 0.56429 to 0.56429, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6671 - acc: 0.5737 - val_loss: 0.6765 - val_acc: 0.5643\n",
      "Epoch 4/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6653 - acc: 0.5743\n",
      "Epoch 00004: val_acc improved from 0.56429 to 0.56439, saving model to best_model.h5\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6654 - acc: 0.5744 - val_loss: 0.6791 - val_acc: 0.5644\n",
      "Epoch 5/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6649 - acc: 0.5749\n",
      "Epoch 00005: val_acc did not improve from 0.56439\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6650 - acc: 0.5746 - val_loss: 0.6787 - val_acc: 0.5644\n",
      "Epoch 6/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6642 - acc: 0.5748\n",
      "Epoch 00006: val_acc did not improve from 0.56439\n",
      "150/150 [==============================] - 3s 20ms/step - loss: 0.6643 - acc: 0.5747 - val_loss: 0.6819 - val_acc: 0.5642\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6644 - acc: 0.5747\n",
      "Epoch 00007: val_acc improved from 0.56439 to 0.56448, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 20ms/step - loss: 0.6644 - acc: 0.5747 - val_loss: 0.6804 - val_acc: 0.5645\n",
      "Epoch 8/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.6641 - acc: 0.5750\n",
      "Epoch 00008: val_acc did not improve from 0.56448\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.6641 - acc: 0.5750 - val_loss: 0.6834 - val_acc: 0.5644\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6636 - acc: 0.5750\n",
      "Epoch 00009: val_acc improved from 0.56448 to 0.56458, saving model to best_model.h5\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6636 - acc: 0.5750 - val_loss: 0.6836 - val_acc: 0.5646\n",
      "Epoch 10/30\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.6634 - acc: 0.5746\n",
      "Epoch 00010: val_acc did not improve from 0.56458\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6633 - acc: 0.5751 - val_loss: 0.6843 - val_acc: 0.5640\n",
      "Epoch 11/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6631 - acc: 0.5750\n",
      "Epoch 00011: val_acc did not improve from 0.56458\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6632 - acc: 0.5751 - val_loss: 0.6833 - val_acc: 0.5644\n",
      "Epoch 12/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.6632 - acc: 0.5744\n",
      "Epoch 00012: val_acc did not improve from 0.56458\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.6632 - acc: 0.5751 - val_loss: 0.6873 - val_acc: 0.5645\n",
      "Epoch 00012: early stopping\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6820 - acc: 0.5491\n",
      "테스트 정확도: 0.5491\n",
      "\n",
      "LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5206 - acc: 0.7378\n",
      "Epoch 00001: val_acc improved from -inf to 0.79500, saving model to best_model.h5\n",
      "150/150 [==============================] - 9s 62ms/step - loss: 0.5206 - acc: 0.7378 - val_loss: 0.4641 - val_acc: 0.7950\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3520 - acc: 0.8578\n",
      "Epoch 00002: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.3520 - acc: 0.8578 - val_loss: 0.5014 - val_acc: 0.7733\n",
      "Epoch 3/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.8895\n",
      "Epoch 00003: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 0.2979 - acc: 0.8891 - val_loss: 0.5583 - val_acc: 0.7858\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2474 - acc: 0.9072\n",
      "Epoch 00004: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.2474 - acc: 0.9072 - val_loss: 0.5779 - val_acc: 0.7708\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2168 - acc: 0.9208\n",
      "Epoch 00005: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.2168 - acc: 0.9208 - val_loss: 0.6488 - val_acc: 0.7742\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1911 - acc: 0.9281\n",
      "Epoch 00006: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 10s 65ms/step - loss: 0.1911 - acc: 0.9281 - val_loss: 0.6424 - val_acc: 0.7625\n",
      "Epoch 7/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9327\n",
      "Epoch 00007: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.1755 - acc: 0.9329 - val_loss: 0.7124 - val_acc: 0.7667\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9354\n",
      "Epoch 00008: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 8s 55ms/step - loss: 0.1579 - acc: 0.9350 - val_loss: 0.7198 - val_acc: 0.7725\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1420 - acc: 0.9406\n",
      "Epoch 00009: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.1420 - acc: 0.9406 - val_loss: 0.8065 - val_acc: 0.7575\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1308 - acc: 0.9433- ETA: 0s - loss: 0.1274 -\n",
      "Epoch 00010: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.1308 - acc: 0.9433 - val_loss: 0.8838 - val_acc: 0.7642\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1190 - acc: 0.9464\n",
      "Epoch 00011: val_acc did not improve from 0.79500\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 0.1190 - acc: 0.9464 - val_loss: 1.0336 - val_acc: 0.7483\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.4575 - acc: 0.7939\n",
      "테스트 정확도: 0.7939\n",
      "\n",
      "LSTM_2layer 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5579 - acc: 0.7215\n",
      "Epoch 00001: val_acc improved from -inf to 0.79833, saving model to best_model.h5\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.5579 - acc: 0.7215 - val_loss: 0.4756 - val_acc: 0.7983\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2872 - acc: 0.7459\n",
      "Epoch 00002: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 1.2872 - acc: 0.7459 - val_loss: 0.6020 - val_acc: 0.7058\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 8.1808 - acc: 0.7636\n",
      "Epoch 00003: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 8.1808 - acc: 0.7636 - val_loss: 1.1618 - val_acc: 0.7100\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 12.4985 - acc: 0.7955\n",
      "Epoch 00004: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 12.4985 - acc: 0.7955 - val_loss: 0.5782 - val_acc: 0.7533\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4905 - acc: 0.8345\n",
      "Epoch 00005: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 17s 112ms/step - loss: 0.4905 - acc: 0.8345 - val_loss: 0.5662 - val_acc: 0.7683\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4056 - acc: 0.8426\n",
      "Epoch 00006: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 14s 93ms/step - loss: 0.4056 - acc: 0.8426 - val_loss: 0.6042 - val_acc: 0.7492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3454 - acc: 0.8612\n",
      "Epoch 00007: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 0.3454 - acc: 0.8612 - val_loss: 0.6606 - val_acc: 0.7658\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3116 - acc: 0.8753\n",
      "Epoch 00008: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.3116 - acc: 0.8753 - val_loss: 0.6798 - val_acc: 0.7583\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2913 - acc: 0.8826\n",
      "Epoch 00009: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 0.2913 - acc: 0.8826 - val_loss: 0.6923 - val_acc: 0.7567\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2676 - acc: 0.8935\n",
      "Epoch 00010: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.2676 - acc: 0.8935 - val_loss: 0.7357 - val_acc: 0.7558\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2491 - acc: 0.9008\n",
      "Epoch 00011: val_acc did not improve from 0.79833\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 0.2491 - acc: 0.9008 - val_loss: 0.7718 - val_acc: 0.7675\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.4783 - acc: 0.8004\n",
      "테스트 정확도: 0.8004\n",
      "\n",
      "Bi-LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.5198 - acc: 0.6831\n",
      "Epoch 00001: val_acc improved from -inf to 0.77167, saving model to best_model.h5\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 1.5198 - acc: 0.6831 - val_loss: 0.5901 - val_acc: 0.7717\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.6442 - acc: 0.7755\n",
      "Epoch 00002: val_acc did not improve from 0.77167\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 3.6442 - acc: 0.7755 - val_loss: 0.6381 - val_acc: 0.5917\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 51.4093 - acc: 0.7834\n",
      "Epoch 00003: val_acc improved from 0.77167 to 0.79333, saving model to best_model.h5\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 51.4093 - acc: 0.7834 - val_loss: 1.3001 - val_acc: 0.7933\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.3493 - acc: 0.8170\n",
      "Epoch 00004: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 14s 95ms/step - loss: 2.3493 - acc: 0.8170 - val_loss: 0.9321 - val_acc: 0.7742\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 8545.1807 - acc: 0.8053\n",
      "Epoch 00005: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 18s 120ms/step - loss: 8545.1807 - acc: 0.8053 - val_loss: 0.6804 - val_acc: 0.5100\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.6304 - acc: 0.6210\n",
      "Epoch 00006: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.6304 - acc: 0.6210 - val_loss: 0.6251 - val_acc: 0.6992\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5468 - acc: 0.7945\n",
      "Epoch 00007: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.5468 - acc: 0.7945 - val_loss: 0.5888 - val_acc: 0.7350\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.1682 - acc: 0.8080\n",
      "Epoch 00008: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 4.1682 - acc: 0.8080 - val_loss: 1.8673 - val_acc: 0.6358\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4520 - acc: 0.8243- ETA: 5s  - \n",
      "Epoch 00009: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.4520 - acc: 0.8243 - val_loss: 0.7135 - val_acc: 0.7750\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3355 - acc: 0.8651\n",
      "Epoch 00010: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.3355 - acc: 0.8651 - val_loss: 0.7148 - val_acc: 0.7650\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.1017 - acc: 0.8632\n",
      "Epoch 00011: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 1.1017 - acc: 0.8632 - val_loss: 0.7386 - val_acc: 0.7725\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3136 - acc: 0.8745\n",
      "Epoch 00012: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.3136 - acc: 0.8745 - val_loss: 0.7456 - val_acc: 0.7725\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2936 - acc: 0.8814\n",
      "Epoch 00013: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.2936 - acc: 0.8814 - val_loss: 0.7616 - val_acc: 0.7675\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2795 - acc: 0.8881\n",
      "Epoch 00014: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.2795 - acc: 0.8881 - val_loss: 0.7897 - val_acc: 0.7608\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2669 - acc: 0.8928\n",
      "Epoch 00015: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 17s 113ms/step - loss: 0.2669 - acc: 0.8928 - val_loss: 0.8201 - val_acc: 0.7600\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2582 - acc: 0.8937\n",
      "Epoch 00016: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 0.2582 - acc: 0.8937 - val_loss: 0.8413 - val_acc: 0.7658\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2492 - acc: 0.8945\n",
      "Epoch 00017: val_acc did not improve from 0.79333\n",
      "150/150 [==============================] - 18s 121ms/step - loss: 0.2492 - acc: 0.8945 - val_loss: 0.8700 - val_acc: 0.7583\n",
      "Epoch 00017: early stopping\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 1.8565 - acc: 0.7844\n",
      "테스트 정확도: 0.7844\n",
      "\n",
      "Bi-LSTM 2층 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 159483854848.0000 - acc: 0.5604\n",
      "Epoch 00001: val_acc improved from -inf to 0.52333, saving model to best_model.h5\n",
      "150/150 [==============================] - 31s 210ms/step - loss: 159483854848.0000 - acc: 0.5604 - val_loss: 134499.1562 - val_acc: 0.5233\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 299395.1875 - acc: 0.5654\n",
      "Epoch 00002: val_acc improved from 0.52333 to 0.59250, saving model to best_model.h5\n",
      "150/150 [==============================] - 34s 225ms/step - loss: 299395.1875 - acc: 0.5654 - val_loss: 56769.5000 - val_acc: 0.5925\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 80282.1484 - acc: 0.5929\n",
      "Epoch 00003: val_acc did not improve from 0.59250\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 80282.1484 - acc: 0.5929 - val_loss: 54636.9375 - val_acc: 0.5808\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 63758.4297 - acc: 0.5760\n",
      "Epoch 00004: val_acc did not improve from 0.59250\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 63758.4297 - acc: 0.5760 - val_loss: 257490.1562 - val_acc: 0.4625\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 88677.0859 - acc: 0.6481\n",
      "Epoch 00005: val_acc improved from 0.59250 to 0.72583, saving model to best_model.h5\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 88677.0859 - acc: 0.6481 - val_loss: 123630.4531 - val_acc: 0.7258\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 21024.0684 - acc: 0.6452\n",
      "Epoch 00006: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 21024.0684 - acc: 0.6452 - val_loss: 111705.0156 - val_acc: 0.4908\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 158602.2344 - acc: 0.5814\n",
      "Epoch 00007: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 158602.2344 - acc: 0.5814 - val_loss: 144583.5312 - val_acc: 0.6067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 95228.9141 - acc: 0.5672\n",
      "Epoch 00008: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 26s 177ms/step - loss: 95228.9141 - acc: 0.5672 - val_loss: 18020.2207 - val_acc: 0.5892\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 120725.7969 - acc: 0.5428\n",
      "Epoch 00009: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 120725.7969 - acc: 0.5428 - val_loss: 229134.0000 - val_acc: 0.5850\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 141242.7812 - acc: 0.5835\n",
      "Epoch 00010: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 30s 199ms/step - loss: 141242.7812 - acc: 0.5835 - val_loss: 70908.2578 - val_acc: 0.6167\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 2568281.0000 - acc: 0.4936\n",
      "Epoch 00011: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 26s 174ms/step - loss: 2568281.0000 - acc: 0.4936 - val_loss: 540581.4375 - val_acc: 0.4133\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 1301869952.0000 - acc: 0.4151\n",
      "Epoch 00012: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 30s 201ms/step - loss: 1301869952.0000 - acc: 0.4151 - val_loss: 13854.3594 - val_acc: 0.4600\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 39285.5117 - acc: 0.6093\n",
      "Epoch 00013: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 39285.5117 - acc: 0.6093 - val_loss: 137966.2344 - val_acc: 0.5125\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 91390.7422 - acc: 0.5195\n",
      "Epoch 00014: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 91390.7422 - acc: 0.5195 - val_loss: 93663.2656 - val_acc: 0.5367\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 28689.7305 - acc: 0.5522\n",
      "Epoch 00015: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 28689.7305 - acc: 0.5522 - val_loss: 24997.2324 - val_acc: 0.4717\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 30260.6523 - acc: 0.5731\n",
      "Epoch 00016: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 27s 178ms/step - loss: 30260.6523 - acc: 0.5731 - val_loss: 33714.0898 - val_acc: 0.6025\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 29436.2715 - acc: 0.5770\n",
      "Epoch 00017: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 30s 197ms/step - loss: 29436.2715 - acc: 0.5770 - val_loss: 29535.9824 - val_acc: 0.5275\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 108039.7578 - acc: 0.5101\n",
      "Epoch 00018: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 32s 212ms/step - loss: 108039.7578 - acc: 0.5101 - val_loss: 188244.0625 - val_acc: 0.5250\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 49801424.0000 - acc: 0.5310\n",
      "Epoch 00019: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 31s 204ms/step - loss: 49801424.0000 - acc: 0.5310 - val_loss: 1136081.2500 - val_acc: 0.5125\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 477103.8438 - acc: 0.5391\n",
      "Epoch 00020: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 477103.8438 - acc: 0.5391 - val_loss: 358055.3438 - val_acc: 0.6017\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 537349.0000 - acc: 0.6379\n",
      "Epoch 00021: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 537349.0000 - acc: 0.6379 - val_loss: 686148.4375 - val_acc: 0.6733\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 308342.5625 - acc: 0.6756\n",
      "Epoch 00022: val_acc did not improve from 0.72583\n",
      "150/150 [==============================] - 31s 208ms/step - loss: 308342.5625 - acc: 0.6756 - val_loss: 290994.0000 - val_acc: 0.6683\n",
      "Epoch 00022: early stopping\n",
      "63/63 [==============================] - 4s 66ms/step - loss: 82557.1328 - acc: 0.7504\n",
      "테스트 정확도: 0.7504\n",
      "\u0001D-CNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.5368 - acc: 0.7392\n",
      "Epoch 00001: val_acc improved from -inf to 0.78917, saving model to best_model.h5\n",
      "150/150 [==============================] - 3s 19ms/step - loss: 0.5347 - acc: 0.7400 - val_loss: 0.4729 - val_acc: 0.7892\n",
      "Epoch 2/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.3554 - acc: 0.8614\n",
      "Epoch 00002: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 5s 36ms/step - loss: 0.3546 - acc: 0.8618 - val_loss: 0.5167 - val_acc: 0.7867\n",
      "Epoch 3/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.9035\n",
      "Epoch 00003: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 3s 20ms/step - loss: 0.2659 - acc: 0.9035 - val_loss: 0.5651 - val_acc: 0.7883\n",
      "Epoch 4/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9290\n",
      "Epoch 00004: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 3s 17ms/step - loss: 0.2045 - acc: 0.9285 - val_loss: 0.5850 - val_acc: 0.7700\n",
      "Epoch 5/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9436\n",
      "Epoch 00005: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 4s 27ms/step - loss: 0.1657 - acc: 0.9429 - val_loss: 0.6638 - val_acc: 0.7725\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1413 - acc: 0.9500- \n",
      "Epoch 00006: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 4s 25ms/step - loss: 0.1413 - acc: 0.9500 - val_loss: 0.7238 - val_acc: 0.7725\n",
      "Epoch 7/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9588- ETA: 1s - loss:\n",
      "Epoch 00007: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 3s 19ms/step - loss: 0.1144 - acc: 0.9587 - val_loss: 0.7466 - val_acc: 0.7683\n",
      "Epoch 8/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9593\n",
      "Epoch 00008: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 4s 26ms/step - loss: 0.0994 - acc: 0.9593 - val_loss: 0.8546 - val_acc: 0.7667\n",
      "Epoch 9/30\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9643\n",
      "Epoch 00009: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 4s 28ms/step - loss: 0.0785 - acc: 0.9644 - val_loss: 0.9309 - val_acc: 0.7650\n",
      "Epoch 10/30\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9673\n",
      "Epoch 00010: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 3s 18ms/step - loss: 0.0637 - acc: 0.9671 - val_loss: 1.0440 - val_acc: 0.7550\n",
      "Epoch 11/30\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9688\n",
      "Epoch 00011: val_acc did not improve from 0.78917\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.0574 - acc: 0.9687 - val_loss: 1.2034 - val_acc: 0.7592\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4637 - acc: 0.7989\n",
      "테스트 정확도: 0.7989\n"
     ]
    }
   ],
   "source": [
    "test_result = []\n",
    "token_name = ['token_okt1', 'token_okt2', 'token_mecab1', 'token_mecab2']\n",
    "for token in token_name:\n",
    "    print(token , \"방식 진행합니다.\\n\")\n",
    "    X_train, y_train, X_test, y_test, vocab_size = convert_input(token,2)\n",
    "    padding_len(55, X_train)\n",
    "    padding_len(55, X_test)\n",
    "    X_train, X_test,max_len = padding(55)\n",
    "    \n",
    "    if token =='token_okt1':\n",
    "        token = \"okt\"\n",
    "    elif token =='token_okt2':\n",
    "        token = \"okt_조사제거\"\n",
    "    elif token =='token_mecab1':\n",
    "        token = \"mecab\"\n",
    "    elif token =='token_mecab2':\n",
    "        token = \"mecab_조사제거\"\n",
    "    \n",
    "    print(\"\\nDNN 모델 진행합니다.\")\n",
    "    DNN()\n",
    "    print(\"\\nLSTM 모델 진행합니다.\")\n",
    "    lstm()\n",
    "    print(\"\\nLSTM_2layer 모델 진행합니다.\")\n",
    "    lstm_2_layer()\n",
    "    print(\"\\nBi-LSTM 모델 진행합니다.\")\n",
    "    bidirectional_lstm()\n",
    "    print(\"\\nBi-LSTM 2층 모델 진행합니다.\")\n",
    "    bidirectional_lstm_2()\n",
    "    print(\"\\1D-CNN 모델 진행합니다.\")\n",
    "    cnn_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:40:47.481364Z",
     "start_time": "2021-04-20T08:40:47.467892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>형태소 분석</th>\n",
       "      <th>모델명</th>\n",
       "      <th>test 정확도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okt</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.546701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okt</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.792896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okt</td>\n",
       "      <td>LSTM_2layer</td>\n",
       "      <td>0.789895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>okt</td>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.770385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okt</td>\n",
       "      <td>Bi-LSTM-2</td>\n",
       "      <td>0.510255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>okt</td>\n",
       "      <td>1D-CNN</td>\n",
       "      <td>0.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>okt_조사제거</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.537605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>okt_조사제거</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.798899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>okt_조사제거</td>\n",
       "      <td>LSTM_2layer</td>\n",
       "      <td>0.781891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>okt_조사제거</td>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.775388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>okt_조사제거</td>\n",
       "      <td>Bi-LSTM-2</td>\n",
       "      <td>0.781891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>okt_조사제거</td>\n",
       "      <td>1D-CNN</td>\n",
       "      <td>0.798399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mecab</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.565037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mecab</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.806403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mecab</td>\n",
       "      <td>LSTM_2layer</td>\n",
       "      <td>0.789895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mecab</td>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.795398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mecab</td>\n",
       "      <td>Bi-LSTM-2</td>\n",
       "      <td>0.786893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mecab</td>\n",
       "      <td>1D-CNN</td>\n",
       "      <td>0.797899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mecab_조사제거</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.549084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mecab_조사제거</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.793897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mecab_조사제거</td>\n",
       "      <td>LSTM_2layer</td>\n",
       "      <td>0.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mecab_조사제거</td>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.784392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mecab_조사제거</td>\n",
       "      <td>Bi-LSTM-2</td>\n",
       "      <td>0.750375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mecab_조사제거</td>\n",
       "      <td>1D-CNN</td>\n",
       "      <td>0.798899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        형태소 분석          모델명  test 정확도\n",
       "0          okt          DNN  0.546701\n",
       "1          okt         LSTM  0.792896\n",
       "2          okt  LSTM_2layer  0.789895\n",
       "3          okt      Bi-LSTM  0.770385\n",
       "4          okt    Bi-LSTM-2  0.510255\n",
       "5          okt       1D-CNN  0.799400\n",
       "6     okt_조사제거          DNN  0.537605\n",
       "7     okt_조사제거         LSTM  0.798899\n",
       "8     okt_조사제거  LSTM_2layer  0.781891\n",
       "9     okt_조사제거      Bi-LSTM  0.775388\n",
       "10    okt_조사제거    Bi-LSTM-2  0.781891\n",
       "11    okt_조사제거       1D-CNN  0.798399\n",
       "12       mecab          DNN  0.565037\n",
       "13       mecab         LSTM  0.806403\n",
       "14       mecab  LSTM_2layer  0.789895\n",
       "15       mecab      Bi-LSTM  0.795398\n",
       "16       mecab    Bi-LSTM-2  0.786893\n",
       "17       mecab       1D-CNN  0.797899\n",
       "18  mecab_조사제거          DNN  0.549084\n",
       "19  mecab_조사제거         LSTM  0.793897\n",
       "20  mecab_조사제거  LSTM_2layer  0.800400\n",
       "21  mecab_조사제거      Bi-LSTM  0.784392\n",
       "22  mecab_조사제거    Bi-LSTM-2  0.750375\n",
       "23  mecab_조사제거       1D-CNN  0.798899"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_result,columns=['형태소 분석','모델명','test 정확도'])\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
